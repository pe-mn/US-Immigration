{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FAQs** <br>\n",
    "- How can I read multiple .sas7bdat files into the  data frame? <br>\n",
    "https://knowledge.udacity.com/questions/280093\n",
    "- Feedback on sample data architecture and database schema <br>\n",
    "https://knowledge.udacity.com/questions/131241\n",
    "- How do I troubleshoot \"Error: Vpc associated with db subnet group does not exist\" <br>\n",
    "https://knowledge.udacity.com/questions/65605"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# United States Immigration  \n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## Table of Contents\n",
    "<ul>\n",
    "<li><a href=\"#intro\"><b>Project Summary</b></a></li>\n",
    "<li><a href=\"#step1\">Step 1: Scope the Project and Gather Data</a></li>\n",
    "<li><a href=\"#step2\">Step 2: Explore and Assess the Data</a></li>\n",
    "<li><a href=\"#step3\">Step 3: Define the Data Model</a></li>\n",
    "<li><a href=\"#step4\">Step 4: Run ETL to Model the Data</a></li>\n",
    "<li><a href=\"#step5\">Step 5: Complete Project Write Up</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project Summary\n",
    "Preparing the data for \"Immigration\" and \"U.S. State Demographics\" Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import pickle\n",
    "from zipfile import ZipFile \n",
    "from pprint import pprint\n",
    "import re\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step1'></a>\n",
    "### Step 1: Scope the Project and Gather Data\n",
    "<ul>\n",
    " <li><a href=\"#intro\">Project Summary</a></li>\n",
    " <li><a href=\"#step1\"><b>Step 1: Scope the Project and Gather Data</b></a></li>\n",
    " <li><a href=\"#step2\">Step 2: Explore and Assess the Data</a></li>\n",
    " <li><a href=\"#step3\">Step 3: Define the Data Model</a></li>\n",
    " <li><a href=\"#step4\">Step 4: Run ETL to Model the Data</a></li>\n",
    " <li><a href=\"#step5\">Step 5: Complete Project Write Up</a></li>\n",
    " </ul>\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "\n",
    "<a href='https://travel.trade.gov/research/reports/i94/historical/2016.html'><b>I94 Immigration Data:</b></a>\n",
    "- This data comes from the US National Tourism and Trade Office. \n",
    "- A data dictionary is included in the workspace. \n",
    "- There's a sample file so you can take a look at the data in csv format before reading it all in. \n",
    "- You do not have to use the entire dataset, just use what you need to accomplish the goal you set at the beginning of the project.\n",
    "- https://i94.cbp.dhs.gov/I94/#/home\n",
    "- The immigration data and the global temperate data is in an attached disk.\n",
    "- You can access the immigration data in a folder with the following path: ../../data/18-83510-I94-Data-**2016**/. \n",
    "- There's a file for each month of the year. An example file name is i94_apr16_sub.sas7bdat.\n",
    "\n",
    "**What is a Form I-94?**\n",
    "- Form I-94 is the DHS Arrival/Departure Record issued to aliens who are admitted to the U.S.,\n",
    "- who are adjusting status while in the U.S. or extending their stay, among other things. \n",
    "- A CBP officer generally attaches the I-94 to the non-immigrant visitor's passport upon U.S. entry.\n",
    "<br><br>\n",
    "\n",
    "<a href='https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data'><b>World Temperature Data:</b></a>\n",
    "- This dataset came from Kaggle. \n",
    "<br><br>\n",
    "\n",
    "<a href='https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/'><b>U.S. City Demographic Data:</b></a>\n",
    "- This data comes from OpenSoft. \n",
    "- This dataset contains information about the demographics of all US cities and census-designated places with a population greater or equal to 65,000. \n",
    "- This data comes from the US Census Bureau's **2015** American Community Survey.\n",
    "<br><br>\n",
    "\n",
    "<a href='https://datahub.io/core/airport-codes#data'><b>Airport Code Table:</b></a>\n",
    "- This is a simple table of airport codes and corresponding cities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To read from local machine**, <br>\n",
    "We need to download the file,'i94_apr16_sub.sas7bdat' <br>\n",
    "- <font color='red'>It is very memory consuming to do the project in local machine.</font><br>\n",
    "- It is better to use udacity workspace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### 1- Immigration Data Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 28)\n",
      "Duration: 0.05954098701477051 Seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4084316.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JL</td>\n",
       "      <td>5.658267e+10</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4422636.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>20568.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160423</td>\n",
       "      <td>MTR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*GA</td>\n",
       "      <td>9.436200e+10</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode  \\\n",
       "0  4084316.0  2016.0     4.0   209.0   209.0     HHW  20566.0      1.0   \n",
       "1  4422636.0  2016.0     4.0   582.0   582.0     MCA  20567.0      1.0   \n",
       "\n",
       "  i94addr  depdate  i94bir  i94visa  count  dtadfile visapost occup entdepa  \\\n",
       "0      HI  20573.0    61.0      2.0    1.0  20160422      NaN   NaN       G   \n",
       "1      TX  20568.0    26.0      2.0    1.0  20160423      MTR   NaN       G   \n",
       "\n",
       "  entdepd  entdepu matflag  biryear   dtaddto gender  insnum airline  \\\n",
       "0       O      NaN       M   1955.0  07202016      F     NaN      JL   \n",
       "1       R      NaN       M   1990.0  10222016      M     NaN     *GA   \n",
       "\n",
       "         admnum  fltno visatype  \n",
       "0  5.658267e+10  00782       WT  \n",
       "1  9.436200e+10  XBLNG       B2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read in the data here\n",
    "t0 = time()\n",
    "df = pd.read_csv('input_data/immigration_data_sample.csv')\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "print(df.shape)\n",
    "print(f\"Duration: {time()-t0} Seconds\")\n",
    "\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### 2- Temperature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8599212, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01               6.068                          1.737  Århus   \n",
       "1  1743-12-01                 NaN                            NaN  Århus   \n",
       "2  1744-01-01                 NaN                            NaN  Århus   \n",
       "3  1744-02-01                 NaN                            NaN  Århus   \n",
       "4  1744-03-01                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with ZipFile(\"input_data/data2.zip\") as zipf:\n",
    "    with zipf.open(\"data2/GlobalLandTemperaturesByCity.csv\", \"r\") as f:\n",
    "        df_temp = pd.read_csv(f)\n",
    "        \n",
    "print(df_temp.shape)\n",
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### 3- Airport Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55075, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident      type               name  elevation_ft continent iso_country  \\\n",
       "0   00A  heliport  Total Rf Heliport          11.0       NaN          US   \n",
       "\n",
       "  iso_region municipality gps_code iata_code local_code  \\\n",
       "0      US-PA     Bensalem      00A       NaN        00A   \n",
       "\n",
       "                          coordinates  \n",
       "0  -74.93360137939453, 40.07080078125  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_port = pd.read_csv('input_data/airport-codes_csv.csv')\n",
    "print(df_port.shape)\n",
    "df_port.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### 4- US Cities Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2891, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            City          State  Median Age  Male Population  \\\n",
       "0  Silver Spring       Maryland        33.8          40601.0   \n",
       "1         Quincy  Massachusetts        41.0          44129.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "\n",
       "   Average Household Size State Code                Race  Count  \n",
       "0                    2.60         MD  Hispanic or Latino  25924  \n",
       "1                    2.39         MA               White  58723  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demo = pd.read_csv('input_data/us-cities-demographics.csv', delimiter=';')\n",
    "print(df_demo.shape)\n",
    "df_demo.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a href='https://github.com/saurfang/spark-sas7bdat'>Spark SAS Data Source (sas7bdat --> SAS V7 and Beyond File Extension for a data set)<a>\n",
    "- A library for reading SAS data (.sas7bdat) with Spark. \n",
    "- This packages **allow reading SAS binary file (.sas7bdat) in parallel** as data frame in Spark SQL. \n",
    "- It provides utility to export it as CSV (using spark-csv) or parquet file.\n",
    "- **Note:** this library seems to not be maintained at all, consider using another one if that's for production code.\n",
    "<br><br>\n",
    "https://stackoverflow.com/questions/73890143/get-py4j-protocol-py4jjavaerror-java-lang-noclassdeffounderror-scala-productcm <br>\n",
    "https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.5/hostwin/n0sk6o15955yoen19n9ghdziqw1u.htm <br>\n",
    "https://fileinfo.com/extension/sas7bdat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/11/22 03:29:31 WARN Utils: Your hostname, Mahmouds-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.1.3 instead (on interface en0)\n",
      "22/11/22 03:29:31 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "https://repos.spark-packages.org/ added as a remote repository with the name: repo-1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/mnagy99/opt/anaconda3/lib/python3.8/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/mnagy99/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/mnagy99/.ivy2/jars\n",
      "saurfang#spark-sas7bdat added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-65daf489-c02e-4330-988b-a8361cfd0aa0;1.0\n",
      "\tconfs: [default]\n",
      "\tfound saurfang#spark-sas7bdat;2.0.0-s_2.11 in spark-packages\n",
      "\tfound com.epam#parso;2.0.8 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.5 in central\n",
      "\tfound org.apache.logging.log4j#log4j-api-scala_2.11;2.7 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.11.8 in central\n",
      ":: resolution report :: resolve 398ms :: artifacts dl 12ms\n",
      "\t:: modules in use:\n",
      "\tcom.epam#parso;2.0.8 from central in [default]\n",
      "\torg.apache.logging.log4j#log4j-api-scala_2.11;2.7 from central in [default]\n",
      "\torg.scala-lang#scala-reflect;2.11.8 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.5 from central in [default]\n",
      "\tsaurfang#spark-sas7bdat;2.0.0-s_2.11 from spark-packages in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   5   |   0   |   0   |   0   ||   5   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-65daf489-c02e-4330-988b-a8361cfd0aa0\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 5 already retrieved (0kB/14ms)\n",
      "22/11/22 03:29:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.3:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7feab0da1100>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Immigration Data\n",
    "- There's a file for each month of the year.\n",
    "- **Note:** these files are large, so you'll have to think about how to process and aggregate them efficiently.\n",
    "<br><br>\n",
    "- The most important decision for modeling with this data is thinking about the **level of aggregation**. \n",
    "- Do you want to aggregate by airport by month? Or **by city by year?** \n",
    "- This level of aggregation will influence how you join the data with other datasets. \n",
    "- There isn't a right answer, it all depends on what you want your final dataset to look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t0 = time()\n",
    "# fname = \"../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat\"\n",
    "# df_spark = spark.read.format('com.github.saurfang.sas.spark').load(fname)\n",
    "# print(f\"Count: {df_spark.count()} Records\")\n",
    "# print(f\"Duration: {time()-t0} Seconds\")\n",
    "\n",
    "# # df_spark.printSchema()\n",
    "# df_spark.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Using Pandas.read_sas --> Slowest Read\n",
    "# t0 = time()\n",
    "# fname = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "# df = pd.read_sas(fname, 'sas7bdat', encoding=\"ISO-8859-1\")\n",
    "# print(df.shape)\n",
    "# print(f\"Duration: {time()-t0} Seconds\")\n",
    "\n",
    "# df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 3096313 Records\n",
      "Duration: 6.9363932609558105 Seconds\n",
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/11/22 03:29:44 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5748517.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>QF</td>\n",
       "      <td>9.495387e+10</td>\n",
       "      <td>00011</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5748518.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>20591.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>VA</td>\n",
       "      <td>9.495562e+10</td>\n",
       "      <td>00007</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode  \\\n",
       "0  5748517.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "1  5748518.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "\n",
       "  i94addr  depdate  ...  entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0      CA  20582.0  ...     None        M   1976.0  10292016      F   None   \n",
       "1      NV  20591.0  ...     None        M   1984.0  10292016      F   None   \n",
       "\n",
       "  airline        admnum  fltno visatype  \n",
       "0      QF  9.495387e+10  00011       B1  \n",
       "1      VA  9.495562e+10  00007       B1  \n",
       "\n",
       "[2 rows x 28 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#write to parquet --> Fastest Read\n",
    "# Apache Parquet:\n",
    "# is an open source, column-oriented data file format \n",
    "# designed for efficient data storage and retrieval.\n",
    "\n",
    "t0 = time()\n",
    "# df_spark.write.parquet(\"sas_data\")\n",
    "df_spark=spark.read.parquet(\"input_data/sas_data\")\n",
    "print(f\"Count: {df_spark.count()} Records\")\n",
    "print(f\"Duration: {time()-t0} Seconds\")\n",
    "\n",
    "df_spark.printSchema()\n",
    "df_spark.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step2'></a>\n",
    "### Step 2: Explore and Assess the Data\n",
    "<ul>\n",
    " <li><a href=\"#intro\">Project Summary</a></li>\n",
    " <li><a href=\"#step1\">Step 1: Scope the Project and Gather Data</a></li>\n",
    " <li><a href=\"#step2\"><b>Step 2: Explore and Assess the Data</b></a></li>\n",
    " <li><a href=\"#step3\">Step 3: Define the Data Model</a></li>\n",
    " <li><a href=\"#step4\">Step 4: Run ETL to Model the Data</a></li>\n",
    " <li><a href=\"#step5\">Step 5: Complete Project Write Up</a></li>\n",
    " </ul>\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Transformation and Loading:**\n",
    "\n",
    "**fact_immigration:**\n",
    "- Convert Dates (sas / string) to DateTime\n",
    "- Add Visa Categories (1=Business - 2=Pleasure - 3=Student)\n",
    "- Add travel modes (1=Air - 2=Sea - 3=Land - 9=Not Reported)\n",
    "- Write to parquet\n",
    "\n",
    "**dim_time:**\n",
    "- Get all the arrival dates from the immigration data_set;\n",
    "- extract year, month, day, week from the date and insert all the values in the dim_time table;\n",
    "- Write to parquet\n",
    "\n",
    "**dim_city_demographics:**\n",
    "- Rename Columns\n",
    "- Write to parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Character|Description|\n",
    "|-|:-|\n",
    "| \\ |Signals a special sequence (can also be used to escape special characters)|\n",
    "| ( ) |Capture and group|\n",
    "| . | Any character (except newline character)|\n",
    "| * | Zero or more occurrences |\n",
    "\n",
    "\\'(.*)\\' --> Any group of characters between single quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "659\n"
     ]
    }
   ],
   "source": [
    "# Create list of valid ports\n",
    "i94_sas_label_descriptions_fname = \"I94_SAS_Labels_Descriptions.SAS\"\n",
    "with open(i94_sas_label_descriptions_fname) as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "re_obj = re.compile(r\"\\'(.*)\\'.*\\'(.*)\\'\")\n",
    "valid_ports = {}\n",
    "for line in lines[302:961]:\n",
    "    results = re_obj.search(line)\n",
    "#     valid_ports[results[1]]=[results[2]]\n",
    "    valid_ports[results.group(1)] = results.group(2)\n",
    "print(len(valid_ports))\n",
    "# pprint(valid_ports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{<br>\n",
    "'ABE': 'ABERDEEN, WA          ', <br>\n",
    "'ABG': 'ALBURG, VT            ', <br>\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check invalid ports in our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|i94port|count|\n",
      "+-------+-----+\n",
      "|    INT|   32|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(df_spark.filter(~df_spark.i94port.isin(list(valid_ports.keys()))).count())\n",
    "# df_spark.filter(~df_spark.i94port.isin(list(valid_ports.keys()))).select('i94port').show()\n",
    "\n",
    "df_spark.filter(~df_spark.i94port.isin(list(valid_ports.keys()))).groupBy('i94port').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(659, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>port</th>\n",
       "      <th>location</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALC</td>\n",
       "      <td>[ALCAN,  AK]</td>\n",
       "      <td>ALCAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANC</td>\n",
       "      <td>[ANCHORAGE,  AK]</td>\n",
       "      <td>ANCHORAGE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  port          location       city\n",
       "0  ALC      [ALCAN,  AK]      ALCAN\n",
       "1  ANC  [ANCHORAGE,  AK]  ANCHORAGE"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "port_df = pd.DataFrame(valid_ports.items(), columns=['port', 'location'])\n",
    "port_df.location = port_df.location.str.strip().str.split(',')\n",
    "print(port_df.shape)\n",
    "port_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>port</th>\n",
       "      <th>location</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>MAP</td>\n",
       "      <td>[MARIPOSA AZ]</td>\n",
       "      <td>MARIPOSA AZ</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>BLT</td>\n",
       "      <td>[PACIFIC,  HWY. STATION,  CA]</td>\n",
       "      <td>PACIFIC</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>WAS</td>\n",
       "      <td>[WASHINGTON DC]</td>\n",
       "      <td>WASHINGTON DC</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>WSB</td>\n",
       "      <td>[WARROAD INTL,  SPB,  MN]</td>\n",
       "      <td>WARROAD INTL</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>SPF</td>\n",
       "      <td>[BLACK HILLS,  SPEARFISH,  SD]</td>\n",
       "      <td>BLACK HILLS</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>NK</td>\n",
       "      <td>[No PORT Code (NK)]</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>ADU</td>\n",
       "      <td>[No PORT Code (ADU)]</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>AKT</td>\n",
       "      <td>[No PORT Code (AKT)]</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>LIT</td>\n",
       "      <td>[No PORT Code (LIT)]</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>A2A</td>\n",
       "      <td>[No PORT Code (A2A)]</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    port                        location           city state\n",
       "28   MAP                   [MARIPOSA AZ]    MARIPOSA AZ   N/A\n",
       "49   BLT   [PACIFIC,  HWY. STATION,  CA]        PACIFIC   N/A\n",
       "76   WAS                 [WASHINGTON DC]  WASHINGTON DC   N/A\n",
       "217  WSB       [WARROAD INTL,  SPB,  MN]   WARROAD INTL   N/A\n",
       "385  SPF  [BLACK HILLS,  SPEARFISH,  SD]    BLACK HILLS   N/A\n",
       "..   ...                             ...            ...   ...\n",
       "654   NK             [No PORT Code (NK)]            N/A   N/A\n",
       "655  ADU            [No PORT Code (ADU)]            N/A   N/A\n",
       "656  AKT            [No PORT Code (AKT)]            N/A   N/A\n",
       "657  LIT            [No PORT Code (LIT)]            N/A   N/A\n",
       "658  A2A            [No PORT Code (A2A)]            N/A   N/A\n",
       "\n",
       "[90 rows x 4 columns]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "port_df[port_df.location.apply(lambda x: len(x)) != 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_df['city'] = port_df.location.apply(lambda x: x[0] if not x[0].startswith('No PORT') else 'N/A')\n",
    "port_df['state'] = port_df.location.apply(lambda x: x[1] if len(x)==2 else 'N/A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "['MD' 'MA' 'AL' 'CA' 'NJ' 'IL' 'AZ' 'MO' 'NC' 'PA' 'KS' 'FL' 'TX' 'VA'\n",
      " 'NV' 'CO' 'MI' 'CT' 'MN' 'UT' 'AR' 'TN' 'OK' 'WA' 'NY' 'GA' 'NE' 'KY'\n",
      " 'SC' 'LA' 'NM' 'IA' 'RI' 'PR' 'DC' 'WI' 'OR' 'NH' 'ND' 'DE' 'OH' 'ID'\n",
      " 'IN' 'AK' 'MS' 'HI' 'SD' 'ME' 'MT']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/11/22 09:01:29 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 709264 ms exceeds timeout 120000 ms\n",
      "22/11/22 09:01:30 WARN SparkContext: Killing executors is not supported by current scheduler.\n"
     ]
    }
   ],
   "source": [
    "# Create list of valid states\n",
    "valid_states = df_demo[\"State Code\"].unique()\n",
    "print(len(valid_states))\n",
    "print(valid_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='imm'></a>\n",
    ">#### 1- Immigration Data Sample\n",
    "\n",
    "<ul>\n",
    " <li><a href=\"#imm\"><b>1- Immigration Data Sample</b></a></li>\n",
    " <li><a href=\"#temp\">2- Temperature Data</a></li>\n",
    " <li><a href=\"#air\">3- Airport Codes</a></li>\n",
    " <li><a href=\"#demo\">4- US Cities Demographics</a></li>\n",
    " </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Immigration Data\n",
    "- There's a file for each month of the year.\n",
    "- **Note:** these files are large, so you'll have to think about how to process and aggregate them efficiently.\n",
    "<br><br>\n",
    "- The most important decision for modeling with this data is thinking about the **level of aggregation**. \n",
    "- Do you want to aggregate by airport by month? Or **by city by year?** \n",
    "- This level of aggregation will influence how you join the data with other datasets. \n",
    "- There isn't a right answer, it all depends on what you want your final dataset to look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in df.columns:\n",
    "#     print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4084316.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JL</td>\n",
       "      <td>5.658267e+10</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4422636.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>20568.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160423</td>\n",
       "      <td>MTR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*GA</td>\n",
       "      <td>9.436200e+10</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode  \\\n",
       "0  4084316.0  2016.0     4.0   209.0   209.0     HHW  20566.0      1.0   \n",
       "1  4422636.0  2016.0     4.0   582.0   582.0     MCA  20567.0      1.0   \n",
       "\n",
       "  i94addr  depdate  i94bir  i94visa  count  dtadfile visapost occup entdepa  \\\n",
       "0      HI  20573.0    61.0      2.0    1.0  20160422      NaN   NaN       G   \n",
       "1      TX  20568.0    26.0      2.0    1.0  20160423      MTR   NaN       G   \n",
       "\n",
       "  entdepd  entdepu matflag  biryear   dtaddto gender  insnum airline  \\\n",
       "0       O      NaN       M   1955.0  07202016      F     NaN      JL   \n",
       "1       R      NaN       M   1990.0  10222016      M     NaN     *GA   \n",
       "\n",
       "         admnum  fltno visatype  \n",
       "0  5.658267e+10  00782       WT  \n",
       "1  9.436200e+10  XBLNG       B2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Read in the data here\n",
    "# t0 = time()\n",
    "# df = pd.read_csv('input_data/immigration_data_sample.csv')\n",
    "# df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "# print(df.shape)\n",
    "# print(f\"Duration: {time()-t0} Seconds\")\n",
    "\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3668.0    3\n",
       "3943.0    3\n",
       "3576.0    2\n",
       "3517.0    2\n",
       "3882.0    1\n",
       "Name: insnum, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.insnum.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STU    2\n",
       "PHA    1\n",
       "OTH    1\n",
       "Name: occup, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.occup.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: entdepu, dtype: int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.entdepu.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 28 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   cicid     1000 non-null   float64\n",
      " 1   i94yr     1000 non-null   float64\n",
      " 2   i94mon    1000 non-null   float64\n",
      " 3   i94cit    1000 non-null   float64\n",
      " 4   i94res    1000 non-null   float64\n",
      " 5   i94port   1000 non-null   object \n",
      " 6   arrdate   1000 non-null   float64\n",
      " 7   i94mode   1000 non-null   float64\n",
      " 8   i94addr   941 non-null    object \n",
      " 9   depdate   951 non-null    float64\n",
      " 10  i94bir    1000 non-null   float64\n",
      " 11  i94visa   1000 non-null   float64\n",
      " 12  count     1000 non-null   float64\n",
      " 13  dtadfile  1000 non-null   int64  \n",
      " 14  visapost  382 non-null    object \n",
      " 15  occup     4 non-null      object \n",
      " 16  entdepa   1000 non-null   object \n",
      " 17  entdepd   954 non-null    object \n",
      " 18  entdepu   0 non-null      float64\n",
      " 19  matflag   954 non-null    object \n",
      " 20  biryear   1000 non-null   float64\n",
      " 21  dtaddto   1000 non-null   object \n",
      " 22  gender    859 non-null    object \n",
      " 23  insnum    35 non-null     float64\n",
      " 24  airline   967 non-null    object \n",
      " 25  admnum    1000 non-null   float64\n",
      " 26  fltno     992 non-null    object \n",
      " 27  visatype  1000 non-null   object \n",
      "dtypes: float64(15), int64(1), object(12)\n",
      "memory usage: 218.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 States\n"
     ]
    }
   ],
   "source": [
    "print(f\"{df.i94addr.nunique()} States\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['visapost'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    1000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['count'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.i94addr.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.i94port.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "https://dhhr.wv.gov/bcf/Services/familyassistance/PolicyManual/Documents/Chapter%2018/ch18_1.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I94CIT & I94RES - This format shows all the valid and invalid codes for processing value i94cntyl \n",
    "- cntryl --> Country of Living (I think!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| - | Col | Description |\n",
    "|-|-:|:-|\n",
    "|1|cicid|Application number / Citizenship and Immigration C...|\n",
    "|**2**|**i94yr**|**4 digit year (Application issue or arrival year, I think)**|\n",
    "|**3**|**i94mon**|**Numeric month (Application issue or arrival month, I think)**|\n",
    "|4|i94cit|Country Immigrant is Originally From (country of citizernship, I think!)|\n",
    "|5|i94res|Country of Immigrant Residence (coutnry of residence, I think!)|\n",
    "|6|i94port|AIR / SEAPORT of entry into the US (I think!)<br> ('XXX': 'NOT REPORTED/UNKNOWN' - '888': 'UNIDENTIFED AIR / SEAPORT' -'UNK': 'UNKNOWN POE')|\n",
    "|**7**|**arrdate**|**Arrival Date in the USA (SAS date)**|\n",
    "|8|i94mode| (1: 'Air' - 2: 'Sea' - 3: 'Land' -  9: 'Not reported') |\n",
    "|9|i94addr|U.S. State / Address of Immigrant Inside USA (I think!) <br> ('99'='All Other Codes') <br> actually representing the final address of the migrants, that is where they currently live in the US.|\n",
    "|**10**|**depdate**|**Departure Date from the USA (SAS date)**|\n",
    "|**11**|**i94bir**|**Age of Respondent in Years**|\n",
    "|12|i94visa|Visa codes collapsed into three categories <br> (Business - Pleasure - Student)|\n",
    "|13|count|Used for summary statistics|\n",
    "|**14**|**dtadfile**|**Character Date Field - Date added to I-94 Files - CIC does not use**|\n",
    "|15|visapost|Department of State where where Visa was issued - CIC does not use <br> This is where your visa was issued. It will be a U.S. embassy or U.S. consulate.|\n",
    "|16|occup|Occupation that will be performed in U.S. - CIC does not use|\n",
    "|17|entdepa|Arrival Flag - admitted or paroled into the U.S. - CIC does not use|\n",
    "|18|entdepd|Departure Flag - Departed, lost I-94 or is deceased - CIC does not use|\n",
    "|19|entdepu|Update Flag - Either apprehended, overstayed, adjusted to perm residence - CIC does not use|\n",
    "|20|matflag|Match flag - Match of arrival and departure records|\n",
    "|**21**|**biryear**|**4 digit year of birth**|\n",
    "|**22**|**dtaddto**|**Character Date Field - Date to which admitted to U.S. (allowed to stay until) - CIC does not use <br>  visa expiration date  <br>**|\n",
    "|23|gender|Non-immigrant sex|\n",
    "|24|insnum|INS number (Immigration and Naturalization Service)|\n",
    "|25|airline|Airline used to arrive in U.S.|\n",
    "|26|admnum|Admission Number - An 11-digit number assigned to an alien when he enters the Unites States.|\n",
    "|27|fltno|Flight number of Airline used to arrive in U.S.|\n",
    "|28|visatype|VISATYPE - Class of admission legally admitting the non-immigrant to temporarily stay in U.S.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MEX    28\n",
       "BNS    21\n",
       "BGT    14\n",
       "SPL    14\n",
       "GUZ    13\n",
       "Name: visapost, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.visapost.value_counts().head()\n",
    "\n",
    "# This is where your visa was issued. It will be a U.S. embassy or U.S. consulate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WT     443\n",
       "B2     356\n",
       "WB      91\n",
       "B1      61\n",
       "GMT     27\n",
       "F1      10\n",
       "CP       5\n",
       "E2       3\n",
       "F2       3\n",
       "M1       1\n",
       "Name: visatype, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.visatype.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://visaservices.duke.edu/categories/b2-wt\n",
    "- **B-1** visitor for business or medical treatment (valid for up to a year)\n",
    "    - Usually 6 months. In addition, you can apply for extension of stay for another 6 months. Reason for extension must be consistent with the terms and conditions of your original status.\n",
    "    - **WB Visa Waiver for Business:**\n",
    "        - travel to the United States for business for stays of 90 days or less without obtaining a visa.\n",
    "- **B-2**  visitor for pleasure, tourism, visiting friends or relatives (valid for up to a year)\n",
    "    - Such type of visa is normally issued up from a period of 1 month to 10 years. The visitor will be allowed to stay up to 6 months each entry, but can apply to extend the stay in the U.S. even longer.\n",
    "    - **WT Visa Waiver for Tourism:** \n",
    "        - travel to the United States for tourism for stays of 90 days or less without obtaining a visa. \n",
    "- **F-1** \n",
    "    - available only to full-time, enrolled students working toward a degree, certificate or specified course of study at a United States institution of higher education.\n",
    "- **F-2** \n",
    "    - F-2 visas allow spouses and minor children of F-1 students to enter the U.S. to live with the F-1 student for the duration of the educational program. However, this does not allow you to work in the U.S. or study full-time.\n",
    "- **GMT** Global Marine Travel\n",
    "- **CP** Continued Presence\n",
    "- **E2** \n",
    "    - The E-2 Investor Visa allows an individual to enter and work in the United States based on an investment in a U.S. business. The E2 visa is valid for three months to five years and can be extended indefinitely. \n",
    "    - The investment must be \"substantial\", although there is no legally defined minimum.\n",
    "- **M-1**\n",
    "    - The M-1 visa is a type of student visa in the U.S. reserved for international students attending vocational schools and technical schools. \n",
    "    - non-academic or “vocational study” --> Mechanical, language, cooking classes, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.siam-legal.com/us-visa/how-long-will-your-u-s-visa-allow-you-to-stay-in-the-u-s/ <br>\n",
    "The visa expiration date is shown on the visa along with the visa issuance date. The time between visa issuance and expiration date is called your visa validity.\n",
    "\n",
    "**How long does a visa last?**\n",
    "Usually 6 months. In addition, you can apply for extension of stay for another 6 months. Reason for extension must be consistent with the terms and conditions of your original status. Such type of visa is normally issued up from a period of 1 month to 10 years.\n",
    "\n",
    "**B1 Visa** – visitor for business or medical treatment\n",
    "\n",
    "**B2 Visa** – visitor for pleasure, tourism, visiting friends or relatives\n",
    "\n",
    "**D Visa** – crew members\n",
    "- If the travel purpose is crew service, the length of stay allowed in the U.S. is maximum of 29 days. No extensions of stay or changes to another status.\n",
    "\n",
    "**F Visa** – academic students\n",
    "- Holders of this visa may remain in the U.S. as long as he/she remains enrolled, in a full-time study, or in an educational program at an approved school. Conditions include making normal progress towards completing the course of study and in compliance with all the terms of the visa category. There is a 60-day grace period to prepare to leave the United States. No extension application needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Immigration DATA Wrangling with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: This is just a Sample\n",
    "df.cicid.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: This is just a Sample\n",
    "df.cicid.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://knowledge.udacity.com/questions/552714 <br>\n",
    "**There are two factors affecting ADNUM.**\n",
    "- ADNUM (Admission Number) is given to the individual every time he enters the country.\n",
    "- An individual cannot enter the same country and have the same admission number two different times. You may want to check for duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: This is just a Sample\n",
    "df.admnum.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "826"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['i94cit'] == df['i94res']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1195600.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20571.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>07052016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>5.578047e+10</td>\n",
       "      <td>00464</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>232708.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20546.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20554.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>06302016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BA</td>\n",
       "      <td>5.547449e+10</td>\n",
       "      <td>00117</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2711583.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>FTL</td>\n",
       "      <td>20559.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20565.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>07132016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VES</td>\n",
       "      <td>5.617586e+10</td>\n",
       "      <td>93724</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1387607.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>BOS</td>\n",
       "      <td>20552.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20560.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>07062016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AF</td>\n",
       "      <td>5.583339e+10</td>\n",
       "      <td>00338</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4668286.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>746.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>SEA</td>\n",
       "      <td>20568.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>20571.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>10232016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.443560e+10</td>\n",
       "      <td>00143</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode  \\\n",
       "2   1195600.0  2016.0     4.0   148.0   112.0     OGG  20551.0      1.0   \n",
       "7    232708.0  2016.0     4.0   113.0   135.0     NYC  20546.0      1.0   \n",
       "12  2711583.0  2016.0     4.0   148.0   112.0     FTL  20559.0      2.0   \n",
       "14  1387607.0  2016.0     4.0   148.0   112.0     BOS  20552.0      1.0   \n",
       "18  4668286.0  2016.0     4.0   746.0   158.0     SEA  20568.0      1.0   \n",
       "\n",
       "   i94addr  depdate  ...  entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "2       FL  20571.0  ...      NaN        M   1940.0  07052016      M    NaN   \n",
       "7       NY  20554.0  ...      NaN        M   1983.0  06302016      F    NaN   \n",
       "12     NaN  20565.0  ...      NaN        M   1962.0  07132016      F    NaN   \n",
       "14      MA  20560.0  ...      NaN        M   1982.0  07062016      F    NaN   \n",
       "18      NV  20571.0  ...      NaN        M   1970.0  10232016      M    NaN   \n",
       "\n",
       "   airline        admnum  fltno visatype  \n",
       "2       LH  5.578047e+10  00464       WT  \n",
       "7       BA  5.547449e+10  00117       WT  \n",
       "12     VES  5.617586e+10  93724       WT  \n",
       "14      AF  5.583339e+10  00338       WT  \n",
       "18      DL  9.443560e+10  00143       B2  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['i94cit'] != df['i94res']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>Convert Dates (sas / string) to DateTime</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4084316.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>2016-04-22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>2016-04-29</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JL</td>\n",
       "      <td>5.658267e+10</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4422636.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160423</td>\n",
       "      <td>MTR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*GA</td>\n",
       "      <td>9.436200e+10</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1195600.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>2016-04-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>2016-04-27</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>07052016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>5.578047e+10</td>\n",
       "      <td>00464</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5291768.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>2016-05-07</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160428</td>\n",
       "      <td>DOH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>10272016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QR</td>\n",
       "      <td>9.478970e+10</td>\n",
       "      <td>00739</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>985523.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>CHM</td>\n",
       "      <td>2016-04-06</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>2016-04-09</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Z</td>\n",
       "      <td>K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>07042016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.232257e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cicid   i94yr  i94mon  i94cit  i94res i94port    arrdate  i94mode  \\\n",
       "0  4084316.0  2016.0     4.0   209.0   209.0     HHW 2016-04-22      1.0   \n",
       "1  4422636.0  2016.0     4.0   582.0   582.0     MCA 2016-04-23      1.0   \n",
       "2  1195600.0  2016.0     4.0   148.0   112.0     OGG 2016-04-07      1.0   \n",
       "3  5291768.0  2016.0     4.0   297.0   297.0     LOS 2016-04-28      1.0   \n",
       "4   985523.0  2016.0     4.0   111.0   111.0     CHM 2016-04-06      3.0   \n",
       "\n",
       "  i94addr    depdate  i94bir  i94visa  count  dtadfile visapost occup entdepa  \\\n",
       "0      HI 2016-04-29    61.0      2.0    1.0  20160422      NaN   NaN       G   \n",
       "1      TX 2016-04-24    26.0      2.0    1.0  20160423      MTR   NaN       G   \n",
       "2      FL 2016-04-27    76.0      2.0    1.0  20160407      NaN   NaN       G   \n",
       "3      CA 2016-05-07    25.0      2.0    1.0  20160428      DOH   NaN       G   \n",
       "4      NY 2016-04-09    19.0      2.0    1.0  20160406      NaN   NaN       Z   \n",
       "\n",
       "  entdepd  entdepu matflag  biryear   dtaddto gender  insnum airline  \\\n",
       "0       O      NaN       M   1955.0  07202016      F     NaN      JL   \n",
       "1       R      NaN       M   1990.0  10222016      M     NaN     *GA   \n",
       "2       O      NaN       M   1940.0  07052016      M     NaN      LH   \n",
       "3       O      NaN       M   1991.0  10272016      M     NaN      QR   \n",
       "4       K      NaN       M   1997.0  07042016      F     NaN     NaN   \n",
       "\n",
       "         admnum  fltno visatype  \n",
       "0  5.658267e+10  00782       WT  \n",
       "1  9.436200e+10  XBLNG       B2  \n",
       "2  5.578047e+10  00464       WT  \n",
       "3  9.478970e+10  00739       B2  \n",
       "4  4.232257e+10   LAND       WT  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert Dates from SAS to DateTime\n",
    "df['arrdate'] = pd.to_datetime(df['arrdate'], unit='D', origin='1960-01-01')\n",
    "df['depdate'] = pd.to_datetime(df['depdate'], unit='D', origin='1960-01-01')\n",
    "\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dtaddto'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70     D/S\n",
       "238    D/S\n",
       "274    D/S\n",
       "337    D/S\n",
       "415    D/S\n",
       "538    D/S\n",
       "591    D/S\n",
       "615    D/S\n",
       "621    D/S\n",
       "684    D/S\n",
       "791    D/S\n",
       "934    D/S\n",
       "964    D/S\n",
       "Name: dtaddto, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Corrupted Date Fields\n",
    "mask = df['dtaddto'].apply(lambda x: len(str(x))) < 8\n",
    "df['dtaddto'][mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>3599863.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>HOU</td>\n",
       "      <td>2016-04-19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>2016-07-04</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1974.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WN</td>\n",
       "      <td>9.399116e+10</td>\n",
       "      <td>02831</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>513953.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>2016-04-03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>2016-06-22</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BR</td>\n",
       "      <td>9.268561e+10</td>\n",
       "      <td>00012</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         cicid   i94yr  i94mon  i94cit  i94res i94port    arrdate  i94mode  \\\n",
       "70   3599863.0  2016.0     4.0   582.0   582.0     HOU 2016-04-19      1.0   \n",
       "238   513953.0  2016.0     4.0   268.0   268.0     LOS 2016-04-03      1.0   \n",
       "\n",
       "    i94addr    depdate  ...  entdepu  matflag  biryear  dtaddto gender insnum  \\\n",
       "70       TX 2016-07-04  ...      NaN        M   1974.0      D/S      F    NaN   \n",
       "238      CA 2016-06-22  ...      NaN        M   1997.0      D/S      M    NaN   \n",
       "\n",
       "    airline        admnum  fltno visatype  \n",
       "70       WN  9.399116e+10  02831       F1  \n",
       "238      BR  9.268561e+10  00012       F1  \n",
       "\n",
       "[2 rows x 28 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[mask]\n",
    "df[df['dtaddto'] == 'D/S'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[~(df['dtaddto'] == 'D/S')]\n",
    "# df['dtaddto'][mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4084316.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>2016-04-22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>2016-04-29</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-04-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>2016-04-22</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JL</td>\n",
       "      <td>5.658267e+10</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4422636.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>MTR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*GA</td>\n",
       "      <td>9.436200e+10</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cicid   i94yr  i94mon  i94cit  i94res i94port    arrdate  i94mode  \\\n",
       "0  4084316.0  2016.0     4.0   209.0   209.0     HHW 2016-04-22      1.0   \n",
       "1  4422636.0  2016.0     4.0   582.0   582.0     MCA 2016-04-23      1.0   \n",
       "\n",
       "  i94addr    depdate  i94bir  i94visa  count    dtadfile visapost occup  \\\n",
       "0      HI 2016-04-29    61.0      2.0    1.0  2016-04-22      NaN   NaN   \n",
       "1      TX 2016-04-24    26.0      2.0    1.0  2016-04-23      MTR   NaN   \n",
       "\n",
       "  entdepa entdepd  entdepu matflag  biryear     dtaddto gender  insnum  \\\n",
       "0       G       O      NaN       M   1955.0  2016-04-22      F     NaN   \n",
       "1       G       R      NaN       M   1990.0  2016-04-23      M     NaN   \n",
       "\n",
       "  airline        admnum  fltno visatype  \n",
       "0      JL  5.658267e+10  00782       WT  \n",
       "1     *GA  9.436200e+10  XBLNG       B2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/27506367/python-pandas-integer-yyyymmdd-to-datetime\n",
    "\n",
    "df['dtadfile'] = df['dtadfile'].apply(lambda x: pd.to_datetime(str(x), format='%Y%m%d')).dt.date\n",
    "\n",
    "# df['dtaddto'] = df['dtaddto'].apply(lambda x: pd.to_datetime(str(x), format='%m%d%Y') if x!='D/S' else x).dt.date\n",
    "df['dtaddto'] = df['dtadfile'].apply(lambda x: pd.to_datetime(str(x), infer_datetime_format=True) if x!='D/S' else x).dt.date\n",
    "\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Immigration DATA Wrangling with SPARK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark.createOrReplaceTempView('immigration')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Check for NaNs</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/44627386/how-to-find-count-of-null-and-nan-values-for-each-column-in-a-pyspark-dataframe\n",
    "\n",
    "- \"isnan()\" is a function of the pysparq.sql.function package, so you have to set which column you want to use as an argument of the function. \n",
    "- \"isNull()\" belongs to pyspark.sql.Column package, so what you have to do is \"yourColumn.isNull()\" \n",
    "\n",
    "https://medium.com/@allenhuang1996/whats-the-difference-between-null-and-nan-in-python-a1af20d523ce <br>\n",
    "- NaN: Not a Number\n",
    "- None: A Python Object (empty object).\n",
    "- Pandas automatically converts the None to a NaN value.\n",
    "\n",
    "- None means Nothing, Nothing is a concept that describes the absence of anything at all. \n",
    "- Nothing is sometimes confused with Null, but they are very different concepts \n",
    "- because Nothing means absence of anything, while Null means unknown (you do not know if there is a thing or not)\n",
    "- null is often defined to be 0 in those languages, but null in Python is different. Python uses the keyword None to define null objects and variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 3096313 Records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239</td>\n",
       "      <td>152592</td>\n",
       "      <td>142457</td>\n",
       "      <td>802</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1881250</td>\n",
       "      <td>3088187</td>\n",
       "      <td>238</td>\n",
       "      <td>138429</td>\n",
       "      <td>3095921</td>\n",
       "      <td>138429</td>\n",
       "      <td>802</td>\n",
       "      <td>477</td>\n",
       "      <td>414269</td>\n",
       "      <td>2982605</td>\n",
       "      <td>83627</td>\n",
       "      <td>0</td>\n",
       "      <td>19549</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid  i94yr  i94mon  i94cit  i94res  i94port  arrdate  i94mode  i94addr  \\\n",
       "0      0      0       0       0       0        0        0      239   152592   \n",
       "\n",
       "   depdate  i94bir  i94visa  count  dtadfile  visapost    occup  entdepa  \\\n",
       "0   142457     802        0      0         1   1881250  3088187      238   \n",
       "\n",
       "   entdepd  entdepu  matflag  biryear  dtaddto  gender   insnum  airline  \\\n",
       "0   138429  3095921   138429      802      477  414269  2982605    83627   \n",
       "\n",
       "   admnum  fltno  visatype  \n",
       "0       0  19549         0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, isnan, when, count, desc\n",
    "\n",
    "print(f\"Count: {df_spark.count()} Records\")\n",
    "\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_spark.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_spark.columns]).toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid  i94yr  i94mon  i94cit  i94res  i94port  arrdate  i94mode  i94addr  \\\n",
       "0      0      0       0       0       0        0        0        0        0   \n",
       "\n",
       "   depdate  i94bir  i94visa  count  dtadfile  visapost  occup  entdepa  \\\n",
       "0        0       0        0      0         0         0      0        0   \n",
       "\n",
       "   entdepd  entdepu  matflag  biryear  dtaddto  gender  insnum  airline  \\\n",
       "0        0        0        0        0        0       0       0        0   \n",
       "\n",
       "   admnum  fltno  visatype  \n",
       "0       0      0         0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_spark.select([count(when(isnan(c), c)).alias(c) for c in df_spark.columns]).toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5748517.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>SYD</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>QF</td>\n",
       "      <td>9.495387e+10</td>\n",
       "      <td>00011</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode  \\\n",
       "0  5748517.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "\n",
       "  i94addr  depdate  i94bir  i94visa  count  dtadfile visapost occup entdepa  \\\n",
       "0      CA  20582.0    40.0      1.0    1.0  20160430      SYD  None       G   \n",
       "\n",
       "  entdepd entdepu matflag  biryear   dtaddto gender insnum airline  \\\n",
       "0       O    None       M   1976.0  10292016      F   None      QF   \n",
       "\n",
       "         admnum  fltno visatype  \n",
       "0  9.495387e+10  00011       B1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_columns', None):\n",
    "    display(spark.sql(\"\"\"\n",
    "                SELECT *\n",
    "                FROM immigration\n",
    "                LIMIT 1\n",
    "    \"\"\").toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:>                                                         (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|count(DISTINCT cicid)|\n",
      "+---------------------+\n",
      "|              3096313|\n",
      "+---------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 17:=============================>                            (2 + 2) / 4]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT COUNT (DISTINCT cicid)\n",
    "    FROM immigration\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|count|\n",
      "+-----+\n",
      "|  1.0|\n",
      "+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 21:=============================>                            (2 + 2) / 4]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT DISTINCT(count)\n",
    "    FROM immigration\n",
    "    LIMIT 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> the column \"count\" contain only one value \"1.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Convert Dates (sas / string) to DateTime</font>\n",
    "https://sparkbyexamples.com/pyspark/pyspark-to_date-convert-string-to-date-format/ <br>\n",
    "https://knowledge.udacity.com/questions/757001 <br>\n",
    "\n",
    "https://knowledge.udacity.com/questions/381099 <br>\n",
    "Yes, that is correct. A udf is not needed in this case since the function is quite simple. Check out this to_date documentationto learn more about it: https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.to_date <br>  \n",
    "**Avoid udf whenever possible, since by using udfs you may end up losing all the optimization Spark does on the Dataframe/Dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 27:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|arrdate|      date|\n",
      "+-------+----------+\n",
      "|20574.0|2016-04-30|\n",
      "|20574.0|2016-04-30|\n",
      "|20574.0|2016-04-30|\n",
      "+-------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Since SaS date is all about the number of days after \"1960, 1, 1\",\n",
    "# All we need to do is to add these days \"timedelta(days=int(x))\" to \"datetime(1960, 1, 1)\"\n",
    "# https://libguides.library.kent.edu/SAS/DatesTime\n",
    "    \n",
    "def convert_dt(x):\n",
    "    try:\n",
    "        start = datetime(1960, 1, 1)\n",
    "        return start + timedelta(days=int(x))\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "# get_date = F.udf(lambda x: convert_dt(x), T.DateType())\n",
    "get_date = F.udf(convert_dt, T.DateType()) # no need for lambda\n",
    "\n",
    "df_spark.select('arrdate', get_date('arrdate').alias(\"date\")).show(3)\n",
    "## Arrival date conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 28:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|arrdate|      date|\n",
      "+-------+----------+\n",
      "|20574.0|2016-04-30|\n",
      "|20574.0|2016-04-30|\n",
      "|20574.0|2016-04-30|\n",
      "+-------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Alternatively, we can use pandas\n",
    "\n",
    "def sas_to_datetime(date):\n",
    "    if date is not None:\n",
    "        return pd.to_timedelta(date, unit='D') + pd.Timestamp('1960-1-1')\n",
    "    \n",
    "# sas_to_datetime_udf = F.udf(lambda x: sas_to_datetime(x), T.DateType())\n",
    "sas_to_datetime_udf = F.udf(sas_to_datetime, T.DateType()) # no need for lambda\n",
    "\n",
    "df_spark.select('arrdate', sas_to_datetime_udf('arrdate').alias(\"date\")).show(3)\n",
    "## Arrival date conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+\n",
      "|depdate|departure_date|\n",
      "+-------+--------------+\n",
      "|20582.0|    2016-05-08|\n",
      "|20591.0|    2016-05-17|\n",
      "|20582.0|    2016-05-08|\n",
      "+-------+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.select('depdate', get_date('depdate').alias(\"departure_date\")).show(3)\n",
    "## Arrival date conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://spark.apache.org/docs/2.3.0/api/sql/index.html#date_add <br>\n",
    "All dates in SAS correspond to the number of days since 1960-01-01. Therfore, we compute the arrival dates by adding arrdate to 1960-01-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_spark = spark.sql(\"SELECT *, date_add(to_date('1960-01-01'), cast(arrdate as int)) AS arrival_date FROM immigration\")\n",
    "# df_spark.createOrReplaceTempView(\"immigration2\")\n",
    "\n",
    "# https://stackoverflow.com/questions/71108605/recursive-view-error-while-using-spark-3-2-0-version\n",
    "# It works with 3.0.1 but looks like the latest version has a bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|arrival_date|\n",
      "+------------+\n",
      "|  2016-04-30|\n",
      "|  2016-04-30|\n",
      "|  2016-04-30|\n",
      "+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# USING SPARK SQL\n",
    "# ----------------\n",
    "# # to_date('1960-01-01') ==> is not needed\n",
    "spark.sql(\"\"\"\n",
    "    SELECT *, date_add('1960-01-01', cast(arrdate as int)) AS arrival_date \n",
    "    FROM immigration\n",
    "\"\"\").createOrReplaceTempView(\"immigration2\")\n",
    "\n",
    "\n",
    "# OR USING SPARK DATAFRAME\n",
    "# -------------------------\n",
    "# https://sparkbyexamples.com/pyspark/pyspark-typeerror-column-is-not-iterable/\n",
    "# TypeError: Column is not iterable\n",
    "\n",
    "# to modify depdate in place\n",
    "df_spark = df_spark.withColumn('arrdate', F.expr(\"date_add('1960-01-01', cast(arrdate as int))\")) \n",
    "df_spark.select(col(\"arrdate\").alias(\"arrival_date\") ).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|count(depdate)|\n",
      "+--------------+\n",
      "|             0|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT count(depdate) \n",
    "    FROM immigration\n",
    "    WHERE depdate IS NULL\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|departure_date|\n",
      "+--------------+\n",
      "|    2016-05-08|\n",
      "|    2016-05-17|\n",
      "|    2016-05-08|\n",
      "+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Since depdate contains null values\n",
    "\n",
    "# USING SPARK SQL\n",
    "# ----------------\n",
    "sql_expr = \"\"\"\n",
    "CASE WHEN depdate >= 1.0 THEN date_add('1960-01-01', cast(depdate as int))\n",
    "     WHEN depdate IS NULL THEN NULL\n",
    "     ELSE 'N/A' \n",
    "END           \n",
    "\"\"\"\n",
    "\n",
    "spark.sql(\"SELECT *,\" + sql_expr + \"AS departure_date FROM immigration2\").createOrReplaceTempView(\"immigration3\")\n",
    "\n",
    "\n",
    "# OR USING SPARK DATAFRAME\n",
    "# -------------------------\n",
    "# https://sparkbyexamples.com/pyspark/pyspark-typeerror-column-is-not-iterable/\n",
    "# TypeError: Column is not iterable\n",
    "\n",
    "# # to modify depdate in place\n",
    "df_spark = df_spark.withColumn('depdate', F.expr(sql_expr)) \n",
    "df_spark.select(col(\"depdate\").alias(\"departure_date\") ).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  df_spark.select(\"depdate\", \n",
    "# when(df_spark.depdate >= 1, F.expr(\"date_add('1960-01-01', cast(depdate as int)) AS departure_date\"))\\\n",
    "# .otherwise('N/A')).show(3)\n",
    "\n",
    "#  df_spark.selectExpr(\"depdate\", sql_expr).show(3)\n",
    "\n",
    "#  df_spark.select(\"depdate\", F.expr(sql_expr)).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       0|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check N/A values in our previous query \n",
    "spark.sql(\"SELECT count(*) FROM immigration3 WHERE immigration3.depdate = 'N/A'\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|count(dtaddto)|\n",
      "+--------------+\n",
      "|             0|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT count(dtaddto) \n",
    "    FROM immigration\n",
    "    WHERE dtaddto IS NULL\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|visa_end_date|\n",
      "+-------------+\n",
      "|   2016-10-29|\n",
      "|   2016-10-29|\n",
      "|   2016-10-29|\n",
      "+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Since dtaddto contains null values\n",
    "\n",
    "# USING SPARK SQL\n",
    "# ---------------\n",
    "spark.sql(\"\"\"\n",
    "SELECT *, \n",
    "       CASE WHEN dtaddto >= 1 THEN to_date(dtaddto, \"MMddyyyy\")\n",
    "            WHEN dtaddto IS NULL THEN NULL\n",
    "            ELSE 'N/A' END AS visa_end_date \n",
    "FROM immigration3\n",
    "\"\"\").createOrReplaceTempView(\"immigration4\")\n",
    "\n",
    "\n",
    "# OR USING SPARK DATAFRAME\n",
    "# -------------------------\n",
    "df_spark = df_spark.withColumn('dtaddto', F.to_date(\"dtaddto\" ,\"MMddyyyy\")) # to modify dtaddto in place\n",
    "df_spark.select(col(\"dtaddto\").alias(\"visa_end_date\") ).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_spark.select( col(\"dtadfile\"), F.to_date(col(\"dtadfile\") ,\"yyyyMMdd\").alias(\"date\") ).show()\n",
    "\n",
    "# We will not use date added to i94 file in the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Add Visa Categories (Business - Pleasure - Student)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql(\"\"\"\n",
    "#     SELECT *, CASE \n",
    "#         WHEN i94visa = 1.0 THEN 'Business' \n",
    "#         WHEN i94visa = 2.0 THEN 'Pleasure'\n",
    "#         WHEN i94visa = 3.0 THEN 'Student'\n",
    "#         ELSE 'N/A' END AS visa_category \n",
    "                        \n",
    "#     FROM immigration4\n",
    "# \"\"\").createOrReplaceTempView(\"immigration5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|visa_category|\n",
      "+-------------+\n",
      "|     Business|\n",
      "|     Business|\n",
      "|     Business|\n",
      "+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# USING SPARK SQL\n",
    "# ----------------\n",
    "sql_expr = \"\"\"\n",
    "CASE WHEN i94visa = 1.0 THEN 'Business' \n",
    "     WHEN i94visa = 2.0 THEN 'Pleasure'\n",
    "     WHEN i94visa = 3.0 THEN 'Student'\n",
    "     ELSE 'N/A' \n",
    "END              \n",
    "\"\"\"\n",
    "\n",
    "spark.sql(\"SELECT *,\" + sql_expr + \"AS visa_category FROM immigration4\").createOrReplaceTempView(\"immigration5\")\n",
    "\n",
    "\n",
    "# OR USING SPARK DATAFRAME\n",
    "# -------------------------\n",
    "# https://sparkbyexamples.com/pyspark/pyspark-typeerror-column-is-not-iterable/\n",
    "# TypeError: Column is not iterable\n",
    "\n",
    "# # to modify i94visa in place\n",
    "df_spark = df_spark.withColumn('i94visa', F.expr(sql_expr)) \n",
    "df_spark.select(col(\"i94visa\").alias(\"visa_category\") ).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+--------+\n",
      "|visa_category|visatype|count(1)|\n",
      "+-------------+--------+--------+\n",
      "|     Business|      B1|  212410|\n",
      "|     Business|      E1|    3743|\n",
      "|     Business|      E2|   19383|\n",
      "|     Business|     GMB|     150|\n",
      "|     Business|       I|    3176|\n",
      "|     Business|      I1|     234|\n",
      "|     Business|      WB|  282983|\n",
      "|     Pleasure|      B2| 1117897|\n",
      "|     Pleasure|      CP|   14758|\n",
      "|     Pleasure|     CPL|      10|\n",
      "|     Pleasure|     GMT|   89133|\n",
      "|     Pleasure|     SBP|      11|\n",
      "|     Pleasure|      WT| 1309059|\n",
      "|      Student|      F1|   39016|\n",
      "|      Student|      F2|    2984|\n",
      "|      Student|      M1|    1317|\n",
      "|      Student|      M2|      49|\n",
      "+-------------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT visa_category, visatype, count(*)\n",
    "FROM immigration5\n",
    "GROUP BY visa_category, visatype\n",
    "ORDER BY visa_category, visatype\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Check that departure_date > arrival_date</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 45:>                                                         (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|     375|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 45:=============================>                            (2 + 2) / 4]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT COUNT(*)\n",
    "    FROM immigration5\n",
    "    WHERE departure_date <= arrival_date\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+-------+------+\n",
      "|arrival_date|departure_date|biryear|i94bir|\n",
      "+------------+--------------+-------+------+\n",
      "|  2016-04-30|    2016-04-29| 1989.0|  27.0|\n",
      "|  2016-04-30|    2016-04-28| 1985.0|  31.0|\n",
      "|  2016-04-30|    2016-04-29| 1979.0|  37.0|\n",
      "|  2016-04-05|    2012-04-14| 1941.0|  75.0|\n",
      "|  2016-04-05|    2016-03-14| 1948.0|  68.0|\n",
      "|  2016-04-14|    2016-03-03| 1956.0|  60.0|\n",
      "|  2016-04-01|    2016-02-28| 1966.0|  50.0|\n",
      "|  2016-04-04|    2016-03-07| 2011.0|   5.0|\n",
      "|  2016-04-01|    2016-03-05| 1975.0|  41.0|\n",
      "|  2016-04-05|    2016-03-07| 1934.0|  82.0|\n",
      "+------------+--------------+-------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT arrival_date, departure_date, biryear, i94bir\n",
    "    FROM immigration5\n",
    "    WHERE departure_date <= arrival_date\n",
    "\"\"\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">- We can not fix these errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # >- Since the number of affected rows is relatively small, we'll simply drop the rows\n",
    "# spark.sql(\"\"\"\n",
    "#     SELECT *\n",
    "#     FROM immigration5\n",
    "#     WHERE departure_date >= arrival_date\n",
    "# \"\"\").createOrReplaceTempView(\"immigration6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check travel modes \n",
    "(1: 'Air' - 2: 'Sea' - 3: 'Land' - 9: 'Not reported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+\n",
      "|i94mode|count(1)|\n",
      "+-------+--------+\n",
      "|   null|     239|\n",
      "|    1.0| 2994505|\n",
      "|    3.0|   66660|\n",
      "|    2.0|   26349|\n",
      "|    9.0|    8560|\n",
      "+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT i94mode, count(*)\n",
    "    FROM immigration5\n",
    "    GROUP BY i94mode\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql(\"\"\"\n",
    "#     SELECT *, CASE \n",
    "#         WHEN i94mode = 1.0 THEN 'Air' \n",
    "#         WHEN i94mode = 2.0 THEN 'Sea'\n",
    "#         WHEN i94mode = 3.0 THEN 'Land'\n",
    "#         WHEN i94mode = 9.0 THEN 'Not Reported'\n",
    "#         ELSE 'N/A' END AS travel_mode \n",
    "#     FROM immigration5\n",
    "# \"\"\").createOrReplaceTempView(\"immigration6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|travel_mode|\n",
      "+-----------+\n",
      "|        Air|\n",
      "|        Air|\n",
      "|        Air|\n",
      "+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# USING SPARK SQL\n",
    "# ----------------\n",
    "sql_expr = \"\"\"\n",
    "CASE  WHEN i94mode = 1.0 THEN 'Air' \n",
    "      WHEN i94mode = 2.0 THEN 'Sea'\n",
    "      WHEN i94mode = 3.0 THEN 'Land'\n",
    "      WHEN i94mode = 9.0 THEN 'Not Reported'\n",
    "      ELSE 'N/A'  \n",
    "END              \n",
    "\"\"\"\n",
    "\n",
    "spark.sql(\"SELECT *,\" + sql_expr + \"AS travel_mode FROM immigration5\").createOrReplaceTempView(\"immigration6\")\n",
    "\n",
    "\n",
    "# OR USING SPARK DATAFRAME\n",
    "# -------------------------\n",
    "# https://sparkbyexamples.com/pyspark/pyspark-typeerror-column-is-not-iterable/\n",
    "# TypeError: Column is not iterable\n",
    "\n",
    "# # to modify i94mode in place\n",
    "df_spark = df_spark.withColumn('i94mode', F.expr(sql_expr)) \n",
    "df_spark.select(col(\"i94mode\").alias(\"travel_mode\") ).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Fill missing age using birth year</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|     802|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT COUNT(*)\n",
    "    FROM immigration6\n",
    "    WHERE i94bir IS NULL\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|count(biryear)|\n",
      "+--------------+\n",
      "|             0|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT COUNT(biryear) \n",
    "    FROM immigration6 \n",
    "    WHERE biryear IS NULL\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|difference|count(1)|\n",
      "+----------+--------+\n",
      "|       0.0| 3095511|\n",
      "+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT (2016-biryear)-i94bir AS difference, count(*) \n",
    "    FROM immigration6 \n",
    "    WHERE i94bir IS NOT NULL \n",
    "    GROUP BY difference\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "| age|\n",
      "+----+\n",
      "|40.0|\n",
      "|32.0|\n",
      "|29.0|\n",
      "+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# USING SPARK SQL\n",
    "# ----------------\n",
    "spark.sql(\"\"\"\n",
    "    SELECT *, (2016 - biryear) AS age                        \n",
    "    FROM immigration6\n",
    "\"\"\").createOrReplaceTempView(\"immigration7\")\n",
    "\n",
    "# spark.sql(\"\"\"\n",
    "#     SELECT *, CASE \n",
    "#         WHEN biryear IS NOT NULL THEN (2016 - biryear) \n",
    "#         ELSE 'N/A' END AS age                        \n",
    "#     FROM immigration6\n",
    "# \"\"\").createOrReplaceTempView(\"immigration7\")\n",
    "\n",
    "\n",
    "# OR USING SPARK DATAFRAME\n",
    "# -------------------------\n",
    "# https://sparkbyexamples.com/pyspark/pyspark-typeerror-column-is-not-iterable/\n",
    "# TypeError: Column is not iterable\n",
    "\n",
    "# # to modify depdate in place\n",
    "df_spark = df_spark.withColumn('i94bir', F.expr(\"2016 - biryear\")) \n",
    "df_spark.select(col(\"i94bir\").alias(\"age\") ).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|age_missing|\n",
      "+-----------+\n",
      "|          0|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT COUNT(age) As age_missing\n",
    "    FROM immigration7 \n",
    "    WHERE age IS NULL\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+\n",
      "|max(biryear)|min(biryear)|\n",
      "+------------+------------+\n",
      "|      2019.0|      1902.0|\n",
      "+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT MAX(biryear), MIN(biryear) FROM immigration6 WHERE biryear IS NOT NULL\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">- this 2019 birth year is an error in the data\n",
    ">- since this data is for 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>departure_date</th>\n",
       "      <th>visa_end_date</th>\n",
       "      <th>visa_category</th>\n",
       "      <th>travel_mode</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5952559.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>AGA</td>\n",
       "      <td>20554.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>5.754531e+10</td>\n",
       "      <td>00001</td>\n",
       "      <td>GMT</td>\n",
       "      <td>2016-04-10</td>\n",
       "      <td>None</td>\n",
       "      <td>2016-05-24</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>Air</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode  \\\n",
       "0  5952559.0  2016.0     4.0   252.0   209.0     AGA  20554.0      1.0   \n",
       "\n",
       "  i94addr  depdate  ...  airline        admnum  fltno visatype arrival_date  \\\n",
       "0    None      NaN  ...     None  5.754531e+10  00001      GMT   2016-04-10   \n",
       "\n",
       "  departure_date visa_end_date visa_category travel_mode  age  \n",
       "0           None    2016-05-24      Pleasure         Air -3.0  \n",
       "\n",
       "[1 rows x 34 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM immigration7 \n",
    "    WHERE biryear > 2016\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+\n",
      "|  age|count(1)|\n",
      "+-----+--------+\n",
      "|114.0|       1|\n",
      "|111.0|       1|\n",
      "|110.0|       1|\n",
      "|109.0|       2|\n",
      "|108.0|       2|\n",
      "|107.0|       1|\n",
      "|105.0|       2|\n",
      "|103.0|       1|\n",
      "|102.0|       4|\n",
      "|101.0|       2|\n",
      "|100.0|      24|\n",
      "| 99.0|      19|\n",
      "| 98.0|      26|\n",
      "| 97.0|      52|\n",
      "| 96.0|      46|\n",
      "| 95.0|      88|\n",
      "| 94.0|     104|\n",
      "| 93.0|     185|\n",
      "| 92.0|     241|\n",
      "| 91.0|     319|\n",
      "+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# frequency of travellers by age\n",
    "spark.sql(\"\"\"\n",
    "    SELECT age, COUNT(*)\n",
    "    FROM immigration7 \n",
    "    WHERE age IS NOT NULL\n",
    "    GROUP BY age\n",
    "    ORDER BY age DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "| age|count(1)|\n",
      "+----+--------+\n",
      "|-3.0|       1|\n",
      "| 0.0|     765|\n",
      "| 1.0|   12747|\n",
      "| 2.0|   14756|\n",
      "| 3.0|   12704|\n",
      "| 4.0|   14411|\n",
      "| 5.0|   15129|\n",
      "| 6.0|   15773|\n",
      "| 7.0|   14233|\n",
      "| 8.0|   14607|\n",
      "| 9.0|   15368|\n",
      "|10.0|   15745|\n",
      "|11.0|   15971|\n",
      "|12.0|   16840|\n",
      "|13.0|   16490|\n",
      "|14.0|   17435|\n",
      "|15.0|   19401|\n",
      "|16.0|   21153|\n",
      "|17.0|   20326|\n",
      "|18.0|   19117|\n",
      "+----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# frequency of travellers by age\n",
    "spark.sql(\"\"\"\n",
    "    SELECT age, COUNT(*)\n",
    "    FROM immigration7 \n",
    "    WHERE age IS NOT NULL\n",
    "    GROUP BY age\n",
    "    ORDER BY age \n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check columns to partition by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 76:>                                                         (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|i94cit|i94addr| count|\n",
      "+------+-------+------+\n",
      "| 135.0|     FL|102647|\n",
      "| 209.0|     HI| 97159|\n",
      "| 111.0|     NY| 81776|\n",
      "| 135.0|     NY| 72099|\n",
      "| 689.0|     FL| 62244|\n",
      "| 245.0|     CA| 57538|\n",
      "| 687.0|     FL| 40878|\n",
      "| 135.0|     CA| 39073|\n",
      "| 254.0|     GU| 38901|\n",
      "| 252.0|     GU| 38026|\n",
      "| 582.0|     CA| 33941|\n",
      "| 438.0|     CA| 33210|\n",
      "| 148.0|     FL| 31517|\n",
      "| 148.0|     NY| 30246|\n",
      "| 111.0|     CA| 29768|\n",
      "| 696.0|     FL| 29370|\n",
      "| 582.0|     FL| 29272|\n",
      "| 691.0|     FL| 27850|\n",
      "| 582.0|     TX| 27773|\n",
      "| 209.0|     CA| 27535|\n",
      "+------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_spark.groupBy(['i94cit', 'i94addr']).count().sort(desc('count')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|i94cit| count|\n",
      "+------+------+\n",
      "| 135.0|360157|\n",
      "| 209.0|206873|\n",
      "| 245.0|191425|\n",
      "| 111.0|188766|\n",
      "| 582.0|175781|\n",
      "| 148.0|157806|\n",
      "| 254.0|137735|\n",
      "| 689.0|129833|\n",
      "| 213.0|110691|\n",
      "| 438.0|109884|\n",
      "| 117.0| 78535|\n",
      "| 123.0| 76920|\n",
      "| 687.0| 69853|\n",
      "| 129.0| 57224|\n",
      "| 691.0| 54120|\n",
      "| 130.0| 45269|\n",
      "| 251.0| 41744|\n",
      "| 692.0| 41349|\n",
      "| 252.0| 41132|\n",
      "| 696.0| 40785|\n",
      "+------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.groupBy(['i94cit']).count().sort(desc('count')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|i94addr| count|\n",
      "+-------+------+\n",
      "|     FL|621701|\n",
      "|     NY|553677|\n",
      "|     CA|470386|\n",
      "|     HI|168764|\n",
      "|   null|152592|\n",
      "|     TX|134321|\n",
      "|     NV|114609|\n",
      "|     GU| 94107|\n",
      "|     IL| 82126|\n",
      "|     NJ| 76531|\n",
      "|     MA| 70486|\n",
      "|     WA| 55792|\n",
      "|     GA| 44663|\n",
      "|     MI| 32101|\n",
      "|     VA| 31399|\n",
      "|     PA| 30293|\n",
      "|     DC| 28228|\n",
      "|     NE| 26574|\n",
      "|     MD| 25360|\n",
      "|     NC| 23375|\n",
      "+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.groupBy(['i94addr']).count().sort(desc('count')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>Check for Duplicated Admission Number</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://knowledge.udacity.com/questions/552714 <br>\n",
    "**There are two factors affecting ADNUM.**\n",
    "- ADNUM (Admission Number) is given to the individual every time he enters the country.\n",
    "- An individual cannot enter the same country and have the same admission number two different times. You may want to check for duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>departure_date</th>\n",
       "      <th>visa_end_date</th>\n",
       "      <th>visa_category</th>\n",
       "      <th>travel_mode</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5754147.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>TOR</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20579.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>H</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>07222016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>RS</td>\n",
       "      <td>5.917124e+10</td>\n",
       "      <td>07612</td>\n",
       "      <td>WB</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>2016-05-05</td>\n",
       "      <td>2016-07-22</td>\n",
       "      <td>Business</td>\n",
       "      <td>Air</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4547695.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20568.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20571.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160424</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>07222016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>KE</td>\n",
       "      <td>5.917124e+10</td>\n",
       "      <td>00081</td>\n",
       "      <td>WB</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>2016-04-27</td>\n",
       "      <td>2016-07-22</td>\n",
       "      <td>Business</td>\n",
       "      <td>Air</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode  \\\n",
       "0  5754147.0  2016.0     4.0   254.0   276.0     TOR  20574.0      1.0   \n",
       "1  4547695.0  2016.0     4.0   254.0   276.0     NYC  20568.0      1.0   \n",
       "\n",
       "  i94addr  depdate  i94bir  i94visa  count  dtadfile visapost occup entdepa  \\\n",
       "0      NY  20579.0    33.0      1.0    1.0  20160430     None  None       H   \n",
       "1      NY  20571.0    33.0      1.0    1.0  20160424     None  None       G   \n",
       "\n",
       "  entdepd entdepu matflag  biryear   dtaddto gender insnum airline  \\\n",
       "0       O    None       M   1983.0  07222016      F   None      RS   \n",
       "1       O    None       M   1983.0  07222016      F   None      KE   \n",
       "\n",
       "         admnum  fltno visatype arrival_date departure_date visa_end_date  \\\n",
       "0  5.917124e+10  07612       WB   2016-04-30     2016-05-05    2016-07-22   \n",
       "1  5.917124e+10  00081       WB   2016-04-24     2016-04-27    2016-07-22   \n",
       "\n",
       "  visa_category travel_mode   age  \n",
       "0      Business         Air  33.0  \n",
       "1      Business         Air  33.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_columns', None):\n",
    "    display(spark.sql(\"\"\"\n",
    "                SELECT *\n",
    "                FROM immigration7\n",
    "                WHERE admnum IN( \n",
    "                    SELECT admnum FROM (\n",
    "                        SELECT admnum, COUNT(*) AS count\n",
    "                        FROM immigration7\n",
    "                        GROUP BY admnum\n",
    "                        HAVING count > 1 \n",
    "                        LIMIT 1) AS temp)\n",
    "    \"\"\").toPandas()\n",
    "      \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admnum</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.917124e+10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.917115e+10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         admnum  count\n",
       "0  5.917124e+10      2\n",
       "1  5.917115e+10      2"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "            SELECT admnum, COUNT(*) AS count\n",
    "            FROM immigration\n",
    "            GROUP BY admnum\n",
    "            HAVING count > 1 \n",
    "            LIMIT 2\n",
    "    \"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 95:=============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|duplicated_admnum|\n",
      "+-----------------+\n",
      "|            19374|\n",
      "+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT COUNT(*) AS duplicated_admnum FROM (\n",
    "        SELECT admnum, COUNT(*) AS count\n",
    "        FROM immigration\n",
    "        GROUP BY admnum\n",
    "        HAVING count > 1    \n",
    "    ) \n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<BR>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www23.statcan.gc.ca/imdb/p3VD.pl?Function=getVD&TVD=53971"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|num_of_states|\n",
      "+-------------+\n",
      "|          457|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT COUNT(DISTINCT(i94addr)) AS num_of_states\n",
    "    FROM immigration\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4712921.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>CHI</td>\n",
       "      <td>20569.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1974.0</td>\n",
       "      <td>07232016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>UA</td>\n",
       "      <td>5.924734e+10</td>\n",
       "      <td>00906</td>\n",
       "      <td>WB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode  \\\n",
       "0  4712921.0  2016.0     4.0   148.0   112.0     CHI  20569.0      1.0   \n",
       "\n",
       "  i94addr  depdate  ...  entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0      52  20573.0  ...     None        M   1974.0  07232016   None   None   \n",
       "\n",
       "  airline        admnum  fltno visatype  \n",
       "0      UA  5.924734e+10  00906       WB  \n",
       "\n",
       "[1 rows x 28 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM immigration\n",
    "    WHERE i94addr=='52'\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|i94addr|count|\n",
      "+-------+-----+\n",
      "|   null|    0|\n",
      "|     06|    1|\n",
      "|     OC|    1|\n",
      "|     PW|    1|\n",
      "|     CG|    1|\n",
      "|     NF|    1|\n",
      "|     EC|    1|\n",
      "|     YH|    1|\n",
      "|     N7|    1|\n",
      "|     FC|    1|\n",
      "|     RO|    1|\n",
      "|     73|    1|\n",
      "|     EV|    1|\n",
      "|     EX|    1|\n",
      "|     JS|    1|\n",
      "|     PD|    1|\n",
      "|     85|    1|\n",
      "|     63|    1|\n",
      "|     52|    1|\n",
      "|     KF|    1|\n",
      "+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT i94addr, COUNT(i94addr) AS count\n",
    "    FROM immigration\n",
    "    GROUP BY i94addr\n",
    "    ORDER BY count\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|i94addr|\n",
      "+-------+\n",
      "|     .N|\n",
      "|     CI|\n",
      "|     SC|\n",
      "|     AZ|\n",
      "|     IC|\n",
      "|     PU|\n",
      "|     UA|\n",
      "|     EA|\n",
      "|     NS|\n",
      "|     KI|\n",
      "|     RO|\n",
      "|     PI|\n",
      "|     LA|\n",
      "|     NL|\n",
      "|     MN|\n",
      "|     BS|\n",
      "|     11|\n",
      "|     NK|\n",
      "|     RE|\n",
      "|     PL|\n",
      "+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT DISTINCT i94addr \n",
    "    FROM immigration\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_immigration = spark.sql(\"\"\"SELECT * FROM immigration7\"\"\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='temp'></a>\n",
    ">#### 2- Temperature Data\n",
    "\n",
    "<ul>\n",
    " <li><a href=\"#imm\">1- Immigration Data Sample</a></li>\n",
    " <li><a href=\"#temp\"><b>2- Temperature Data</b></a></li>\n",
    " <li><a href=\"#air\">3- Airport Codes</a></li>\n",
    " <li><a href=\"#demo\">4- US Cities Demographics</a></li>\n",
    " </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- commercial air travel did't develop until after the second world war in the 1950s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data2/',\n",
       " '__MACOSX/._data2',\n",
       " 'data2/GlobalLandTemperaturesByCountry.csv',\n",
       " '__MACOSX/data2/._GlobalLandTemperaturesByCountry.csv',\n",
       " 'data2/GlobalLandTemperaturesByMajorCity.csv',\n",
       " '__MACOSX/data2/._GlobalLandTemperaturesByMajorCity.csv',\n",
       " 'data2/GlobalLandTemperaturesByState.csv',\n",
       " '__MACOSX/data2/._GlobalLandTemperaturesByState.csv',\n",
       " 'data2/GlobalTemperatures.csv',\n",
       " '__MACOSX/data2/._GlobalTemperatures.csv',\n",
       " 'data2/GlobalLandTemperaturesByCity.csv',\n",
       " '__MACOSX/data2/._GlobalLandTemperaturesByCity.csv']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/22646623/how-to-read-text-files-in-a-zipped-folder-in-python\n",
    "\n",
    "zfile = ZipFile(\"input_data/data2.zip\", 'r')       \n",
    "zfile.namelist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8599212, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0 1743-11-01               6.068                          1.737  Århus   \n",
       "1 1743-12-01                 NaN                            NaN  Århus   \n",
       "2 1744-01-01                 NaN                            NaN  Århus   \n",
       "3 1744-02-01                 NaN                            NaN  Århus   \n",
       "4 1744-03-01                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with ZipFile(\"input_data/data2.zip\") as zipf:\n",
    "    with zipf.open(\"data2/GlobalLandTemperaturesByCity.csv\", \"r\") as f:\n",
    "        df_temp = pd.read_csv(f)\n",
    "\n",
    "df_temp['dt'] = pd.to_datetime(df_temp['dt'])\n",
    "print(df_temp.shape)\n",
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('1743-11-01 00:00:00'), Timestamp('2013-09-01 00:00:00'))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp['dt'].min(), df_temp['dt'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> No temperature data for 2016, so can not be joined with our immigration dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.Country.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3448"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.City.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "India            1014906\n",
       "China             827802\n",
       "United States     687289\n",
       "Brazil            475580\n",
       "Russia            461234\n",
       "Name: Country, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.Country.value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>Filter on US</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(687289, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47555</th>\n",
       "      <td>1820-01-01</td>\n",
       "      <td>2.101</td>\n",
       "      <td>3.217</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47556</th>\n",
       "      <td>1820-02-01</td>\n",
       "      <td>6.926</td>\n",
       "      <td>2.853</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47557</th>\n",
       "      <td>1820-03-01</td>\n",
       "      <td>10.767</td>\n",
       "      <td>2.395</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47558</th>\n",
       "      <td>1820-04-01</td>\n",
       "      <td>17.989</td>\n",
       "      <td>2.202</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47559</th>\n",
       "      <td>1820-05-01</td>\n",
       "      <td>21.809</td>\n",
       "      <td>2.036</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              dt  AverageTemperature  AverageTemperatureUncertainty     City  \\\n",
       "47555 1820-01-01               2.101                          3.217  Abilene   \n",
       "47556 1820-02-01               6.926                          2.853  Abilene   \n",
       "47557 1820-03-01              10.767                          2.395  Abilene   \n",
       "47558 1820-04-01              17.989                          2.202  Abilene   \n",
       "47559 1820-05-01              21.809                          2.036  Abilene   \n",
       "\n",
       "             Country Latitude Longitude  \n",
       "47555  United States   32.95N   100.53W  \n",
       "47556  United States   32.95N   100.53W  \n",
       "47557  United States   32.95N   100.53W  \n",
       "47558  United States   32.95N   100.53W  \n",
       "47559  United States   32.95N   100.53W  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_temp_us = df_temp.query(\"Country == 'United States'\")\n",
    "df_temp_us = df_temp[df_temp.Country == 'United States'].copy(deep=True)\n",
    "print(df_temp_us.shape)\n",
    "df_temp_us.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dt                                   0\n",
       "AverageTemperature               25765\n",
       "AverageTemperatureUncertainty    25765\n",
       "City                                 0\n",
       "Country                              0\n",
       "Latitude                             0\n",
       "Longitude                            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp_us.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "248"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp_us.City.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If longitude < 0 then West, else East.\n",
    "- If latitude < 0 then South, else North."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_format(x):\n",
    "    if x.endswith('N'):\n",
    "        x = float(x[:-1])\n",
    "    elif x.endswith('E'):\n",
    "        x = float(x[:-1])\n",
    "    elif x.endswith('S'):\n",
    "        x = - float(x[:-1])\n",
    "    elif x.endswith('W'):\n",
    "        x = - float(x[:-1])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47555</th>\n",
       "      <td>1820-01-01</td>\n",
       "      <td>2.101</td>\n",
       "      <td>3.217</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95</td>\n",
       "      <td>-100.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47556</th>\n",
       "      <td>1820-02-01</td>\n",
       "      <td>6.926</td>\n",
       "      <td>2.853</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95</td>\n",
       "      <td>-100.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              dt  AverageTemperature  AverageTemperatureUncertainty     City  \\\n",
       "47555 1820-01-01               2.101                          3.217  Abilene   \n",
       "47556 1820-02-01               6.926                          2.853  Abilene   \n",
       "\n",
       "             Country  Latitude  Longitude  \n",
       "47555  United States     32.95    -100.53  \n",
       "47556  United States     32.95    -100.53  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp_us['Latitude'] = df_temp_us['Latitude'].apply(change_format)\n",
    "df_temp_us['Longitude'] = df_temp_us['Longitude'].apply(change_format)\n",
    "df_temp_us.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>Drop Country Column</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "United States    687289\n",
       "Name: Country, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp_us.Country.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp_us.drop(columns=['Country'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>Map City to its State</font>\n",
    "https://github.com/agalea91/city_to_state_dictionary/blob/master/US%20City%20to%20State%20dictionary.ipynb\n",
    "(there are cities with the same name in different states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickle/us_state_to_abbrev.pkl', 'rb') as f:\n",
    "    us_state_to_abbrev = pickle.load(f)\n",
    "    \n",
    "# # invert the dictionary\n",
    "# abbrev_to_us_state = dict(map(reversed, us_state_to_abbrev.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('pickle/city_to_state.pkl', 'wb') as f:\n",
    "#     pickle.dump(city_to_state, f)\n",
    "    \n",
    "with open('pickle/city_to_state.pkl', 'rb') as f:\n",
    "    city_to_state = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# city_to_st = {}\n",
    "# for key, value in city_to_state.items():\n",
    "#     try:\n",
    "#         city_to_st[key] = us_state_to_abbrev[value]\n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('pickle/city_to_st.pkl', 'wb') as f:\n",
    "#     pickle.dump(city_to_st, f)\n",
    "    \n",
    "with open('pickle/city_to_st.pkl', 'rb') as f:\n",
    "    city_to_st = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_st(city):\n",
    "    try:\n",
    "        st = city_to_st[city]\n",
    "    except:\n",
    "        st = ''\n",
    "    return st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47555</th>\n",
       "      <td>1820-01-01</td>\n",
       "      <td>2.101</td>\n",
       "      <td>3.217</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>32.95</td>\n",
       "      <td>-100.53</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47556</th>\n",
       "      <td>1820-02-01</td>\n",
       "      <td>6.926</td>\n",
       "      <td>2.853</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>32.95</td>\n",
       "      <td>-100.53</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47557</th>\n",
       "      <td>1820-03-01</td>\n",
       "      <td>10.767</td>\n",
       "      <td>2.395</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>32.95</td>\n",
       "      <td>-100.53</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47558</th>\n",
       "      <td>1820-04-01</td>\n",
       "      <td>17.989</td>\n",
       "      <td>2.202</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>32.95</td>\n",
       "      <td>-100.53</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47559</th>\n",
       "      <td>1820-05-01</td>\n",
       "      <td>21.809</td>\n",
       "      <td>2.036</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>32.95</td>\n",
       "      <td>-100.53</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              dt  AverageTemperature  AverageTemperatureUncertainty     City  \\\n",
       "47555 1820-01-01               2.101                          3.217  Abilene   \n",
       "47556 1820-02-01               6.926                          2.853  Abilene   \n",
       "47557 1820-03-01              10.767                          2.395  Abilene   \n",
       "47558 1820-04-01              17.989                          2.202  Abilene   \n",
       "47559 1820-05-01              21.809                          2.036  Abilene   \n",
       "\n",
       "       Latitude  Longitude State  \n",
       "47555     32.95    -100.53    TX  \n",
       "47556     32.95    -100.53    TX  \n",
       "47557     32.95    -100.53    TX  \n",
       "47558     32.95    -100.53    TX  \n",
       "47559     32.95    -100.53    TX  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# /opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
    "# A value is trying to be set on a copy of a slice from a DataFrame.\n",
    "# Try using .loc[row_indexer,col_indexer] = value instead\n",
    "\n",
    "# The above error raised due to the created view in \"Filter on US\"\n",
    "\n",
    "df_temp_us['State'] = df_temp_us['City'].apply(lambda x: get_st(x))\n",
    "df_temp_us.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>Handle Duplicated Cities</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('pickle/duplicated_cities.pkl', 'rb') as f:\n",
    "    duplicated_cities = pickle.load(f)\n",
    "    \n",
    "len(duplicated_cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 77 duplicated cities in the data with 210454 Counts\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alexandria</td>\n",
       "      <td>39.38</td>\n",
       "      <td>-76.99</td>\n",
       "      <td>3239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arlington</td>\n",
       "      <td>32.95</td>\n",
       "      <td>-96.70</td>\n",
       "      <td>2325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         City  Latitude  Longitude  count\n",
       "0  Alexandria     39.38     -76.99   3239\n",
       "1   Arlington     32.95     -96.70   2325"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicated_df = df_temp_us[df_temp_us.City.isin(duplicated_cities)].groupby(['City', 'Latitude', 'Longitude'])['dt']\\\n",
    ".count().reset_index(name='count')\n",
    "\n",
    "total_count = duplicated_df['count'].sum()\n",
    "print(f'We have {duplicated_df.shape[0]} duplicated cities in the data with {total_count} Counts')\n",
    "duplicated_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://gis.stackexchange.com/questions/372872/max-retries-exceeded-with-url-in-nominatim-with-geopy <br>\n",
    "https://stackoverflow.com/questions/28667684/python-requests-getting-sslerror\n",
    "\n",
    "**Comment the try - except block out to see the error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_states(longs, latts):\n",
    "    ''' Input two 1D lists of floats/ints '''\n",
    "    # a list of states\n",
    "    states = []\n",
    " \n",
    "    for lon, lat in zip(longs, latts):\n",
    "        url = f'https://nominatim.openstreetmap.org/reverse?lat={lat}&lon={lon}&format=json&accept-language=en'\n",
    "        try:\n",
    "            result = requests.get(url=url, verify=False)\n",
    "            result_json = result.json()\n",
    "#             print(result_json)\n",
    "            # get the state name\n",
    "            state = result_json['address']['state']\n",
    "            st = us_state_to_abbrev[state]\n",
    "        except:\n",
    "            # return empty string\n",
    "            st = ''\n",
    "        states.append(st)\n",
    "    return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VA', 'AL']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "get_states([-77.05803, -86.95444], [38.73289, 33.40178])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_df['State'] = get_states(duplicated_df.Longitude, duplicated_df.Latitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>count</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alexandria</td>\n",
       "      <td>39.38</td>\n",
       "      <td>-76.99</td>\n",
       "      <td>3239</td>\n",
       "      <td>MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arlington</td>\n",
       "      <td>32.95</td>\n",
       "      <td>-96.70</td>\n",
       "      <td>2325</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         City  Latitude  Longitude  count State\n",
       "0  Alexandria     39.38     -76.99   3239    MD\n",
       "1   Arlington     32.95     -96.70   2325    TX"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# duplicated_df['State'] = duplicated_df.apply(lambda x: get_states(x.Longitude, x.Latitude), axis=1)\n",
    "duplicated_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brownsville --> NY\n",
      "Corona --> CA\n",
      "Long Beach --> CA\n",
      "Oceanside --> CA\n",
      "Orange --> CA\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>count</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Brownsville</td>\n",
       "      <td>26.52</td>\n",
       "      <td>-96.72</td>\n",
       "      <td>2289</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Corona</td>\n",
       "      <td>32.95</td>\n",
       "      <td>-117.77</td>\n",
       "      <td>1977</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Long Beach</td>\n",
       "      <td>32.95</td>\n",
       "      <td>-117.77</td>\n",
       "      <td>1977</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Oceanside</td>\n",
       "      <td>32.95</td>\n",
       "      <td>-117.77</td>\n",
       "      <td>1977</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Orange</td>\n",
       "      <td>32.95</td>\n",
       "      <td>-117.77</td>\n",
       "      <td>1977</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           City  Latitude  Longitude  count State\n",
       "10  Brownsville     26.52     -96.72   2289      \n",
       "22       Corona     32.95    -117.77   1977      \n",
       "44   Long Beach     32.95    -117.77   1977      \n",
       "54    Oceanside     32.95    -117.77   1977      \n",
       "55       Orange     32.95    -117.77   1977      "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: 4 of the cities have the same Latitude and Longitude\n",
    "# By Checking on Google Maps 32.95, -117.77 --> North Pacific Ocean --> near San Diego, California\n",
    "# By Checking on Google Maps 26.52, -96.72 --> Gulf of Mexico --> near Texas\n",
    "\n",
    "# Brownsville --> Texas\n",
    "# Corona --> California\n",
    "# Long Beach --> California\n",
    "# Oceanside --> California\n",
    "# Brownsville --> California\n",
    "\n",
    "cities = ['Brownsville', 'Corona', 'Long Beach', 'Oceanside', 'Orange']\n",
    "for city in cities:\n",
    "    print(city, '-->', city_to_st[city])\n",
    "\n",
    "duplicated_df[duplicated_df['State'] == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting these missing cities  manually\n",
    "\n",
    "mask = (duplicated_df.Latitude==32.95) & (duplicated_df.Longitude==-117.77)\n",
    "duplicated_df.loc[mask , 'State'] = \"CA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (duplicated_df.Latitude==26.52) & (duplicated_df.Longitude==-96.72)\n",
    "duplicated_df.loc[mask , 'State'] = \"TX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>count</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Brownsville</td>\n",
       "      <td>26.52</td>\n",
       "      <td>-96.72</td>\n",
       "      <td>2289</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Corona</td>\n",
       "      <td>32.95</td>\n",
       "      <td>-117.77</td>\n",
       "      <td>1977</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Long Beach</td>\n",
       "      <td>32.95</td>\n",
       "      <td>-117.77</td>\n",
       "      <td>1977</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Oceanside</td>\n",
       "      <td>32.95</td>\n",
       "      <td>-117.77</td>\n",
       "      <td>1977</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Orange</td>\n",
       "      <td>32.95</td>\n",
       "      <td>-117.77</td>\n",
       "      <td>1977</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           City  Latitude  Longitude  count State\n",
       "10  Brownsville     26.52     -96.72   2289    TX\n",
       "22       Corona     32.95    -117.77   1977    CA\n",
       "44   Long Beach     32.95    -117.77   1977    CA\n",
       "54    Oceanside     32.95    -117.77   1977    CA\n",
       "55       Orange     32.95    -117.77   1977    CA"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicated_df[duplicated_df['City'].isin(cities)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alexandria</td>\n",
       "      <td>39.38</td>\n",
       "      <td>-76.99</td>\n",
       "      <td>MD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         City  Latitude  Longitude State\n",
       "0  Alexandria     39.38     -76.99    MD"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicated_df.drop(columns=['count'], inplace=True)\n",
    "duplicated_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Merge both dataframes and overwrite states\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.update.html\n",
    "\n",
    "# Should have at least one matching index/column label with the original DataFrame. \n",
    "# If a Series is passed, its name attribute must be set, and that will be used as the column name \n",
    "# to align with the original DataFrame.\n",
    "\n",
    "# We must set at least one matching index between both dataframes\n",
    "df_temp_us = df_temp_us.set_index(['City', 'Latitude', 'Longitude'])\n",
    "duplicated_df = duplicated_df.set_index(['City', 'Latitude', 'Longitude'])\n",
    "\n",
    "# without City in the index --> Exception: cannot handle a non-unique multi-index!\n",
    "\n",
    "\n",
    "df_temp_us.update(duplicated_df)\n",
    "\n",
    "# # https://stackoverflow.com/questions/9787853/join-or-merge-with-overwrite-in-pandas\n",
    "# duplicated_df.combine_first(df_temp_us) # Did not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Abilene</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">32.95</th>\n",
       "      <th>-100.53</th>\n",
       "      <td>1820-01-01</td>\n",
       "      <td>2.101</td>\n",
       "      <td>3.217</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-100.53</th>\n",
       "      <td>1820-02-01</td>\n",
       "      <td>6.926</td>\n",
       "      <td>2.853</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   dt  AverageTemperature  \\\n",
       "City    Latitude Longitude                                  \n",
       "Abilene 32.95    -100.53   1820-01-01               2.101   \n",
       "                 -100.53   1820-02-01               6.926   \n",
       "\n",
       "                            AverageTemperatureUncertainty State  \n",
       "City    Latitude Longitude                                       \n",
       "Abilene 32.95    -100.53                            3.217    TX  \n",
       "                 -100.53                            2.853    TX  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp_us.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp_us.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70199</th>\n",
       "      <td>Brownsville</td>\n",
       "      <td>26.52</td>\n",
       "      <td>-96.72</td>\n",
       "      <td>1823-01-01</td>\n",
       "      <td>16.028</td>\n",
       "      <td>2.767</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70200</th>\n",
       "      <td>Brownsville</td>\n",
       "      <td>26.52</td>\n",
       "      <td>-96.72</td>\n",
       "      <td>1823-02-01</td>\n",
       "      <td>15.151</td>\n",
       "      <td>3.087</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              City  Latitude  Longitude         dt  AverageTemperature  \\\n",
       "70199  Brownsville     26.52     -96.72 1823-01-01              16.028   \n",
       "70200  Brownsville     26.52     -96.72 1823-02-01              15.151   \n",
       "\n",
       "       AverageTemperatureUncertainty State  \n",
       "70199                          2.767    TX  \n",
       "70200                          3.087    TX  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = (df_temp_us.Latitude==26.52) & (df_temp_us.Longitude==-96.72)\n",
    "df_temp_us[mask].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>Handle Missing States</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nuevo Laredo    2289\n",
       "Name: City, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp_us[df_temp_us.State == ''].City.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nuevo Laredo    2289\n",
       "Name: City, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp_us[df_temp_us.State == ''].City.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**'Nuevo Laredo': 'Tamaulipas'** <br>\n",
    "The city of Laredo is situated in the U.S. state of Texas on the northern bank of the Rio Grande and Nuevo Laredo is located in the Mexican State of Tamaulipas in the southern bank of the river. This area is also known as the Two Laredos or the Laredo Borderplex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>Filter out 'Nuevo Laredo' Mexican City</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(685000, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>32.95</td>\n",
       "      <td>-100.53</td>\n",
       "      <td>1820-01-01</td>\n",
       "      <td>2.101</td>\n",
       "      <td>3.217</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>32.95</td>\n",
       "      <td>-100.53</td>\n",
       "      <td>1820-02-01</td>\n",
       "      <td>6.926</td>\n",
       "      <td>2.853</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>32.95</td>\n",
       "      <td>-100.53</td>\n",
       "      <td>1820-03-01</td>\n",
       "      <td>10.767</td>\n",
       "      <td>2.395</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>32.95</td>\n",
       "      <td>-100.53</td>\n",
       "      <td>1820-04-01</td>\n",
       "      <td>17.989</td>\n",
       "      <td>2.202</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>32.95</td>\n",
       "      <td>-100.53</td>\n",
       "      <td>1820-05-01</td>\n",
       "      <td>21.809</td>\n",
       "      <td>2.036</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      City  Latitude  Longitude         dt  AverageTemperature  \\\n",
       "0  Abilene     32.95    -100.53 1820-01-01               2.101   \n",
       "1  Abilene     32.95    -100.53 1820-02-01               6.926   \n",
       "2  Abilene     32.95    -100.53 1820-03-01              10.767   \n",
       "3  Abilene     32.95    -100.53 1820-04-01              17.989   \n",
       "4  Abilene     32.95    -100.53 1820-05-01              21.809   \n",
       "\n",
       "   AverageTemperatureUncertainty State  \n",
       "0                          3.217    TX  \n",
       "1                          2.853    TX  \n",
       "2                          2.395    TX  \n",
       "3                          2.202    TX  \n",
       "4                          2.036    TX  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp_us = df_temp_us[~(df_temp_us.City == 'Nuevo Laredo')].copy(deep=True)\n",
    "print(df_temp_us.shape)\n",
    "df_temp_us.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>Groupby dt and State and average</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119056, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>State</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>AL</td>\n",
       "      <td>9.974750</td>\n",
       "      <td>2.328750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>CT</td>\n",
       "      <td>4.668667</td>\n",
       "      <td>1.607000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>FL</td>\n",
       "      <td>17.543857</td>\n",
       "      <td>2.351714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>GA</td>\n",
       "      <td>11.647000</td>\n",
       "      <td>2.280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>IA</td>\n",
       "      <td>1.667500</td>\n",
       "      <td>2.527500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dt State  AverageTemperature  AverageTemperatureUncertainty\n",
       "0 1743-11-01    AL            9.974750                       2.328750\n",
       "1 1743-11-01    CT            4.668667                       1.607000\n",
       "2 1743-11-01    FL           17.543857                       2.351714\n",
       "3 1743-11-01    GA           11.647000                       2.280000\n",
       "4 1743-11-01    IA            1.667500                       2.527500"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp_st = df_temp_us.groupby(['dt', 'State'])[['AverageTemperature', 'AverageTemperatureUncertainty']].mean().reset_index()\n",
    "print(df_temp_st.shape)\n",
    "df_temp_st.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>Or Load GlobalLandTemperaturesByState</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data2/',\n",
       " '__MACOSX/._data2',\n",
       " 'data2/GlobalLandTemperaturesByCountry.csv',\n",
       " '__MACOSX/data2/._GlobalLandTemperaturesByCountry.csv',\n",
       " 'data2/GlobalLandTemperaturesByMajorCity.csv',\n",
       " '__MACOSX/data2/._GlobalLandTemperaturesByMajorCity.csv',\n",
       " 'data2/GlobalLandTemperaturesByState.csv',\n",
       " '__MACOSX/data2/._GlobalLandTemperaturesByState.csv',\n",
       " 'data2/GlobalTemperatures.csv',\n",
       " '__MACOSX/data2/._GlobalTemperatures.csv',\n",
       " 'data2/GlobalLandTemperaturesByCity.csv',\n",
       " '__MACOSX/data2/._GlobalLandTemperaturesByCity.csv']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zfile = ZipFile(\"input_data/data2.zip\", 'r')       \n",
    "zfile.namelist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149745, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>State</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7458</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>10.722</td>\n",
       "      <td>2.898</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7459</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7460</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7461</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7462</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              dt  AverageTemperature  AverageTemperatureUncertainty    State  \\\n",
       "7458  1743-11-01              10.722                          2.898  Alabama   \n",
       "7459  1743-12-01                 NaN                            NaN  Alabama   \n",
       "7460  1744-01-01                 NaN                            NaN  Alabama   \n",
       "7461  1744-02-01                 NaN                            NaN  Alabama   \n",
       "7462  1744-03-01                 NaN                            NaN  Alabama   \n",
       "\n",
       "            Country  \n",
       "7458  United States  \n",
       "7459  United States  \n",
       "7460  United States  \n",
       "7461  United States  \n",
       "7462  United States  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from io import StringIO\n",
    "# df_temperature = pd.read_csv(StringIO(f.read().decode()), lineterminator='\\n')\n",
    "\n",
    "with ZipFile(\"input_data/data2.zip\") as zipf:\n",
    "    with zipf.open(\"data2/GlobalLandTemperaturesByState.csv\", \"r\") as f:\n",
    "        df_temperature = pd.read_csv(f)\n",
    "        \n",
    "df_temp_usa = df_temperature[df_temperature.Country == 'United States'].copy(deep=True)\n",
    "print(df_temp_usa.shape)\n",
    "df_temp_usa.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='air'></a>\n",
    ">#### 3- Airport Codes\n",
    "\n",
    "<ul>\n",
    " <li><a href=\"#imm\">1- Immigration Data Sample</a></li>\n",
    " <li><a href=\"#temp\">2- Temperature Data</a></li>\n",
    " <li><a href=\"#air\"><b>3- Airport Codes</b></a></li>\n",
    " <li><a href=\"#demo\">4- US Cities Demographics</a></li>\n",
    " </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**U.S. States**\n",
    "- 'PA': 'PENNSYLVANIA'\n",
    "- 'KS': 'KANSAS'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| - | Col | Description |\n",
    "|-|-|-|\n",
    "|1|ident| identification code |\n",
    "|2|type| type of airport (7 types) <br> (small_airport - medium_airport - large_airport - heliport - seaplane_base - balloonport - closed)|\n",
    "|3|name| Airport Name|\n",
    "|4|elevation_ft| Airport elevation in ft |\n",
    "|5|continent||\n",
    "|6|iso_country||\n",
    "|7|iso_region| US State |\n",
    "|8|municipality| US City <br> A town or district that has local government <br> A municipal airport is an airport owned by a city or municipality. <br> البلدية / المجلس المحلي |\n",
    "|9|gps_code||\n",
    "|10|iata_code| International Air Transport Association airport code |\n",
    "|11|local_code||\n",
    "|12|coordinates||"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An IATA airport code, also known as an IATA location identifier, IATA station code, or simply a location identifier, is a three-character alphanumeric geocode designating many airports and metropolitan areas around the world, defined by the International Air Transport Association."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55075, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident      type               name  elevation_ft continent iso_country  \\\n",
       "0   00A  heliport  Total Rf Heliport          11.0       NaN          US   \n",
       "\n",
       "  iso_region municipality gps_code iata_code local_code  \\\n",
       "0      US-PA     Bensalem      00A       NaN        00A   \n",
       "\n",
       "                          coordinates  \n",
       "0  -74.93360137939453, 40.07080078125  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_port = pd.read_csv('input_data/airport-codes_csv.csv')\n",
    "print(df_port.shape)\n",
    "df_port.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55075 entries, 0 to 55074\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   ident         55075 non-null  object \n",
      " 1   type          55075 non-null  object \n",
      " 2   name          55075 non-null  object \n",
      " 3   elevation_ft  48069 non-null  float64\n",
      " 4   continent     27356 non-null  object \n",
      " 5   iso_country   54828 non-null  object \n",
      " 6   iso_region    55075 non-null  object \n",
      " 7   municipality  49399 non-null  object \n",
      " 8   gps_code      41030 non-null  object \n",
      " 9   iata_code     9189 non-null   object \n",
      " 10  local_code    28686 non-null  object \n",
      " 11  coordinates   55075 non-null  object \n",
      "dtypes: float64(1), object(11)\n",
      "memory usage: 5.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_port.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_port.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_port.iso_country.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>Filter on US</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(247, 12)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before we do that, let's make sure there is no missing data in the iso_county field.\n",
    "df_port[df_port['iso_country'].isna()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AF    247\n",
       "Name: continent, dtype: int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_port[df_port['iso_country'].isna()]['continent'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - All the missing airports data are based in Africa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22757, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                  name  elevation_ft continent  \\\n",
       "0   00A       heliport     Total Rf Heliport          11.0       NaN   \n",
       "1  00AA  small_airport  Aero B Ranch Airport        3435.0       NaN   \n",
       "\n",
       "  iso_country iso_region municipality gps_code iata_code local_code  \\\n",
       "0          US      US-PA     Bensalem      00A       NaN        00A   \n",
       "1          US      US-KS        Leoti     00AA       NaN       00AA   \n",
       "\n",
       "                          coordinates  \n",
       "0  -74.93360137939453, 40.07080078125  \n",
       "1              -101.473911, 38.704022  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_port_us = df_port[df_port.iso_country == 'US'].copy(deep=True)\n",
    "print(df_port_us.shape)\n",
    "df_port_us.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Houston        119\n",
       "Wasilla         68\n",
       "Los Angeles     66\n",
       "Springfield     49\n",
       "Columbus        48\n",
       "Name: municipality, dtype: int64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_port_us.municipality.value_counts().head() # City"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>Exclude 'closed', 'heliport', 'seaplane_base', 'balloonport' Types</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "small_airport     13720\n",
       "heliport           6265\n",
       "closed             1326\n",
       "medium_airport      692\n",
       "seaplane_base       566\n",
       "large_airport       170\n",
       "balloonport          18\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_port_us.type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14582, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                  name  elevation_ft continent  \\\n",
       "1  00AA  small_airport  Aero B Ranch Airport        3435.0       NaN   \n",
       "2  00AK  small_airport          Lowell Field         450.0       NaN   \n",
       "\n",
       "  iso_country iso_region  municipality gps_code iata_code local_code  \\\n",
       "1          US      US-KS         Leoti     00AA       NaN       00AA   \n",
       "2          US      US-AK  Anchor Point     00AK       NaN       00AK   \n",
       "\n",
       "                   coordinates  \n",
       "1       -101.473911, 38.704022  \n",
       "2  -151.695999146, 59.94919968  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No immigration data is collected from balloonports, seaplane bases or heliport \n",
    "# since these means of transportation are used for recreational purposes or very short distances\n",
    "\n",
    "exclude = ['closed', 'heliport', 'seaplane_base', 'balloonport']\n",
    "df_port_us = df_port_us[~df_port_us['type'].isin(exclude)].copy()\n",
    "print(df_port_us.shape)\n",
    "df_port_us.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "small_airport     13720\n",
       "medium_airport      692\n",
       "large_airport       170\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_port_us.type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ident               0\n",
       "type                0\n",
       "name                0\n",
       "elevation_ft       63\n",
       "continent       14582\n",
       "iso_country         0\n",
       "iso_region          0\n",
       "municipality       50\n",
       "gps_code          399\n",
       "iata_code       12717\n",
       "local_code        199\n",
       "coordinates         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_port_us.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 States\n"
     ]
    }
   ],
   "source": [
    "print(f\"{df_port_us.iso_region.nunique()} States\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3937</th>\n",
       "      <td>35TX</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Flying B Ranch Airstrip</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>35TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35TX</td>\n",
       "      <td>-99.82559967041016, 32.48400115966797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7575</th>\n",
       "      <td>6TE2</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Zimmerle Airport</td>\n",
       "      <td>2057.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>6TE2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6TE2</td>\n",
       "      <td>-99.597900390625, 32.270401000977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8704</th>\n",
       "      <td>82TS</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Elmdale Airpark</td>\n",
       "      <td>1775.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>82TS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82TS</td>\n",
       "      <td>-99.650398254395, 32.450099945068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26006</th>\n",
       "      <td>KABI</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Abilene Regional Airport</td>\n",
       "      <td>1791.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>KABI</td>\n",
       "      <td>ABI</td>\n",
       "      <td>ABI</td>\n",
       "      <td>-99.68190002440001, 32.4113006592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26636</th>\n",
       "      <td>KDYS</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>Dyess Air Force Base</td>\n",
       "      <td>1789.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>KDYS</td>\n",
       "      <td>DYS</td>\n",
       "      <td>DYS</td>\n",
       "      <td>-99.854598999, 32.4207992554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27738</th>\n",
       "      <td>KK78</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Abilene Municipal Airport</td>\n",
       "      <td>1152.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>K78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K78</td>\n",
       "      <td>-97.235900878906, 38.904098510742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48147</th>\n",
       "      <td>TX00</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Abilene Executive Airpark</td>\n",
       "      <td>1822.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TX00</td>\n",
       "      <td>-99.62000274658203, 32.44889831542969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48149</th>\n",
       "      <td>TX02</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Portlock Airfield</td>\n",
       "      <td>1780.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TX02</td>\n",
       "      <td>-99.61289978027344, 32.5265007019043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ident            type                       name  elevation_ft  \\\n",
       "3937   35TX   small_airport    Flying B Ranch Airstrip        1750.0   \n",
       "7575   6TE2   small_airport           Zimmerle Airport        2057.0   \n",
       "8704   82TS   small_airport            Elmdale Airpark        1775.0   \n",
       "26006  KABI  medium_airport   Abilene Regional Airport        1791.0   \n",
       "26636  KDYS   large_airport       Dyess Air Force Base        1789.0   \n",
       "27738  KK78   small_airport  Abilene Municipal Airport        1152.0   \n",
       "48147  TX00   small_airport  Abilene Executive Airpark        1822.0   \n",
       "48149  TX02   small_airport          Portlock Airfield        1780.0   \n",
       "\n",
       "      continent iso_country iso_region municipality gps_code iata_code  \\\n",
       "3937        NaN          US      US-TX      Abilene     35TX       NaN   \n",
       "7575        NaN          US      US-TX      Abilene     6TE2       NaN   \n",
       "8704        NaN          US      US-TX      Abilene     82TS       NaN   \n",
       "26006       NaN          US      US-TX      Abilene     KABI       ABI   \n",
       "26636       NaN          US      US-TX      Abilene     KDYS       DYS   \n",
       "27738       NaN          US      US-KS      Abilene      K78       NaN   \n",
       "48147       NaN          US      US-TX      Abilene     TX00       NaN   \n",
       "48149       NaN          US      US-TX      Abilene     TX02       NaN   \n",
       "\n",
       "      local_code                            coordinates  \n",
       "3937        35TX  -99.82559967041016, 32.48400115966797  \n",
       "7575        6TE2      -99.597900390625, 32.270401000977  \n",
       "8704        82TS      -99.650398254395, 32.450099945068  \n",
       "26006        ABI      -99.68190002440001, 32.4113006592  \n",
       "26636        DYS           -99.854598999, 32.4207992554  \n",
       "27738        K78      -97.235900878906, 38.904098510742  \n",
       "48147       TX00  -99.62000274658203, 32.44889831542969  \n",
       "48149       TX02   -99.61289978027344, 32.5265007019043  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_port_us[df_port_us['municipality'] == 'Abilene']\n",
    "\n",
    "# Only one large airport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(853, 12)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_port_us_l = df_port_us[df_port_us['type'].isin(['large_airport', 'medium_airport'])].copy(deep=True)\n",
    "df_port_us_l.dropna(subset=['name', 'local_code'], inplace=True)\n",
    "\n",
    "print(df_port_us_l.shape)\n",
    "(df_port_us_l['iata_code'] == df_port_us_l['local_code']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> iata_code = local_code for all large airports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6188</th>\n",
       "      <td>5A8</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Aleknagik / New Airport</td>\n",
       "      <td>66.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Aleknagik</td>\n",
       "      <td>5A8</td>\n",
       "      <td>WKK</td>\n",
       "      <td>5A8</td>\n",
       "      <td>-158.617996216, 59.2826004028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25825</th>\n",
       "      <td>K79J</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>South Alabama Regional At Bill Benton Field Ai...</td>\n",
       "      <td>310.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Andalusia/Opp</td>\n",
       "      <td>K79J</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79J</td>\n",
       "      <td>-86.393799, 31.3088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26067</th>\n",
       "      <td>KAKR</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Akron Fulton International Airport</td>\n",
       "      <td>1067.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-OH</td>\n",
       "      <td>Akron</td>\n",
       "      <td>KAKR</td>\n",
       "      <td>AKC</td>\n",
       "      <td>AKR</td>\n",
       "      <td>-81.4669036865, 41.0374984741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26168</th>\n",
       "      <td>KBAK</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Columbus Municipal Airport</td>\n",
       "      <td>656.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-IN</td>\n",
       "      <td>Columbus</td>\n",
       "      <td>KBAK</td>\n",
       "      <td>CLU</td>\n",
       "      <td>BAK</td>\n",
       "      <td>-85.8963012695, 39.2619018555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26227</th>\n",
       "      <td>KBKF</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Buckley Air Force Base</td>\n",
       "      <td>5662.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CO</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>KBKF</td>\n",
       "      <td>BFK</td>\n",
       "      <td>BKF</td>\n",
       "      <td>-104.751998901, 39.701698303200004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ident            type  \\\n",
       "6188    5A8  medium_airport   \n",
       "25825  K79J  medium_airport   \n",
       "26067  KAKR  medium_airport   \n",
       "26168  KBAK  medium_airport   \n",
       "26227  KBKF  medium_airport   \n",
       "\n",
       "                                                    name  elevation_ft  \\\n",
       "6188                             Aleknagik / New Airport          66.0   \n",
       "25825  South Alabama Regional At Bill Benton Field Ai...         310.0   \n",
       "26067                 Akron Fulton International Airport        1067.0   \n",
       "26168                         Columbus Municipal Airport         656.0   \n",
       "26227                             Buckley Air Force Base        5662.0   \n",
       "\n",
       "      continent iso_country iso_region   municipality gps_code iata_code  \\\n",
       "6188        NaN          US      US-AK      Aleknagik      5A8       WKK   \n",
       "25825       NaN          US      US-AL  Andalusia/Opp     K79J       NaN   \n",
       "26067       NaN          US      US-OH          Akron     KAKR       AKC   \n",
       "26168       NaN          US      US-IN       Columbus     KBAK       CLU   \n",
       "26227       NaN          US      US-CO         Aurora     KBKF       BFK   \n",
       "\n",
       "      local_code                         coordinates  \n",
       "6188         5A8       -158.617996216, 59.2826004028  \n",
       "25825        79J                 -86.393799, 31.3088  \n",
       "26067        AKR       -81.4669036865, 41.0374984741  \n",
       "26168        BAK       -85.8963012695, 39.2619018555  \n",
       "26227        BKF  -104.751998901, 39.701698303200004  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_port_us_l[df_port_us_l['iata_code'] != df_port_us_l['local_code']].head()\n",
    "\n",
    "# # NaNs != NaNs --> We dropped out NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Columbus        7\n",
       "Jacksonville    6\n",
       "Houston         5\n",
       "Jackson         5\n",
       "Atlanta         4\n",
       "Las Vegas       4\n",
       "Portland        4\n",
       "Sacramento      4\n",
       "Greenville      4\n",
       "San Diego       4\n",
       "Name: municipality, dtype: int64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_port_us_l.municipality.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>Remove US prefix from states</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00AS</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Fulton Airport</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>OK</td>\n",
       "      <td>Alex</td>\n",
       "      <td>00AS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AS</td>\n",
       "      <td>-97.8180194, 34.9428028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00AZ</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Cordes Airport</td>\n",
       "      <td>3810.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Cordes</td>\n",
       "      <td>00AZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AZ</td>\n",
       "      <td>-112.16500091552734, 34.305599212646484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                  name  elevation_ft continent  \\\n",
       "1  00AA  small_airport  Aero B Ranch Airport        3435.0       NaN   \n",
       "2  00AK  small_airport          Lowell Field         450.0       NaN   \n",
       "3  00AL  small_airport          Epps Airpark         820.0       NaN   \n",
       "5  00AS  small_airport        Fulton Airport        1100.0       NaN   \n",
       "6  00AZ  small_airport        Cordes Airport        3810.0       NaN   \n",
       "\n",
       "  iso_country iso_region  municipality gps_code iata_code local_code  \\\n",
       "1          US         KS         Leoti     00AA       NaN       00AA   \n",
       "2          US         AK  Anchor Point     00AK       NaN       00AK   \n",
       "3          US         AL       Harvest     00AL       NaN       00AL   \n",
       "5          US         OK          Alex     00AS       NaN       00AS   \n",
       "6          US         AZ        Cordes     00AZ       NaN       00AZ   \n",
       "\n",
       "                               coordinates  \n",
       "1                   -101.473911, 38.704022  \n",
       "2              -151.695999146, 59.94919968  \n",
       "3    -86.77030181884766, 34.86479949951172  \n",
       "5                  -97.8180194, 34.9428028  \n",
       "6  -112.16500091552734, 34.305599212646484  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_port_us['iso_region'] = df_port_us['iso_region'].apply(lambda x: x[3:])\n",
    "df_port_us.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14582"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_port_us.continent.isnull().sum() # All are NaNs except for 1 value, but we can fill all with \"NA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: continent, dtype: int64)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_port_us.continent.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ident, type, name, elevation_ft, continent, iso_country, iso_region, municipality, gps_code, iata_code, local_code, coordinates]\n",
       "Index: []"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_port_us[df_port_us.continent == 'AS'] # This is Wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Code|Continent name|\n",
    "|-|-|\n",
    "|AF|Africa|\n",
    "|AN|Antarctica|\n",
    "|AS|Asia|\n",
    "|EU|Europe|\n",
    "|NA|North america|\n",
    "|OC|Oceania|\n",
    "|SA|South america|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> What is the difference between ident, gps_code and local_code?!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_port_us['ident'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "399"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_port_us['gps_code'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_port_us['local_code'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4523"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_port_us['ident'] != df_port_us['local_code']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1074"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_port_us['ident'] != df_port_us['gps_code']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>03MT</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Cascade Field</td>\n",
       "      <td>3580.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>MT</td>\n",
       "      <td>Cascade</td>\n",
       "      <td>3MT7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3MT7</td>\n",
       "      <td>-111.71748, 47.267327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>09TA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lazy G Bar Ranch Airport</td>\n",
       "      <td>923.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>TX</td>\n",
       "      <td>Decatur</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09T</td>\n",
       "      <td>-97.497002, 33.282101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>0C7</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Grandpas' Farm Mendota Airport</td>\n",
       "      <td>727.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>IL</td>\n",
       "      <td>Mendota</td>\n",
       "      <td>IL22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IL22</td>\n",
       "      <td>-89.132599, 41.521999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>0D9</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Air Park North</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>MI</td>\n",
       "      <td>Alba</td>\n",
       "      <td>MI30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MI30</td>\n",
       "      <td>-84.9587, 44.958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>0L5</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Goldfield Airport</td>\n",
       "      <td>5680.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>NV</td>\n",
       "      <td>Goldfield</td>\n",
       "      <td>NV50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NV50</td>\n",
       "      <td>-117.236368, 37.722751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ident           type                            name  elevation_ft  \\\n",
       "221  03MT  small_airport                   Cascade Field        3580.0   \n",
       "580  09TA  small_airport        Lazy G Bar Ranch Airport         923.0   \n",
       "636   0C7  small_airport  Grandpas' Farm Mendota Airport         727.0   \n",
       "693   0D9  small_airport                  Air Park North        1170.0   \n",
       "813   0L5  small_airport               Goldfield Airport        5680.0   \n",
       "\n",
       "    continent iso_country iso_region municipality gps_code iata_code  \\\n",
       "221       NaN          US         MT      Cascade     3MT7       NaN   \n",
       "580       NaN          US         TX      Decatur      NaN       NaN   \n",
       "636       NaN          US         IL      Mendota     IL22       NaN   \n",
       "693       NaN          US         MI         Alba     MI30       NaN   \n",
       "813       NaN          US         NV    Goldfield     NV50       NaN   \n",
       "\n",
       "    local_code             coordinates  \n",
       "221       3MT7   -111.71748, 47.267327  \n",
       "580        09T   -97.497002, 33.282101  \n",
       "636       IL22   -89.132599, 41.521999  \n",
       "693       MI30        -84.9587, 44.958  \n",
       "813       NV50  -117.236368, 37.722751  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = (df_port_us['local_code'] != df_port_us['ident']) & (df_port_us['local_code'].notnull())\n",
    "df_port_us[mask].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5II5    2\n",
       "LA36    2\n",
       "46XS    2\n",
       "1TS9    2\n",
       "CVC     2\n",
       "Name: local_code, dtype: int64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_port_us.local_code.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "00AA    1\n",
       "KMO1    1\n",
       "KMKV    1\n",
       "KMKY    1\n",
       "KMLB    1\n",
       "Name: ident, dtype: int64"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_port_us.ident.value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12717"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_port_us.iata_code.isnull().sum() # almost all values are missing!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OCA    1\n",
       "PMH    1\n",
       "POY    1\n",
       "POU    1\n",
       "POF    1\n",
       "Name: iata_code, dtype: int64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_port_us.iata_code.value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='demo'></a>\n",
    ">#### 4- US Cities Demographics\n",
    "\n",
    "<ul>\n",
    " <li><a href=\"#imm\">1- Immigration Data Sample</a></li>\n",
    " <li><a href=\"#temp\">2- Temperature Data</a></li>\n",
    " <li><a href=\"#air\">3- Airport Codes</a></li>\n",
    " <li><a href=\"#demo\"><b>4- US Cities Demographics</b></a></li>\n",
    " </ul>\n",
    " \n",
    " \n",
    "- https://knowledge.udacity.com/questions/552714 \n",
    "- https://www.pewresearch.org/social-trends/2011/01/12/state-population-estimates-and-census-2010-counts-did-they-match/\n",
    "\n",
    "- The Census Bureau's Population Estimates Program (PEP) produces estimates of the population for the United States, states, metropolitan and micropolitan statistical areas, counties, cities, towns, as well as for Puerto Rico and its municipios.\n",
    "- Census population statistics cover age, sex, race, Hispanic origin, migration, ancestry, language use, veterans, as well as population estimates and projections.\n",
    "- Unlike the census, which counts people directly, the State Population Estimates are assembled using government data, including birth and death certificates, immigration estimates and tax-return statistics on people who changed residences.\n",
    "- it greatly increases confidence in the census count if population numbers that are derived using different methods are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2891, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            City          State  Median Age  Male Population  \\\n",
       "0  Silver Spring       Maryland        33.8          40601.0   \n",
       "1         Quincy  Massachusetts        41.0          44129.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "\n",
       "   Average Household Size State Code                Race  Count  \n",
       "0                    2.60         MD  Hispanic or Latino  25924  \n",
       "1                    2.39         MA               White  58723  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demo = pd.read_csv('input_data/us-cities-demographics.csv', delimiter=';')\n",
    "print(df_demo.shape)\n",
    "df_demo.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City                       0\n",
       "State                      0\n",
       "Median Age                 0\n",
       "Male Population            3\n",
       "Female Population          3\n",
       "Total Population           0\n",
       "Number of Veterans        13\n",
       "Foreign-born              13\n",
       "Average Household Size    16\n",
       "State Code                 0\n",
       "Race                       0\n",
       "Count                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demo.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "567 Cities, 49 States\n"
     ]
    }
   ],
   "source": [
    "print(f\"{df_demo.City.nunique()} Cities, {df_demo['State Code'].nunique()} States\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2295"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demo[['City', 'State']].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>2566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2322</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>3917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2578</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>Asian</td>\n",
       "      <td>30473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        City          State  Median Age  Male Population  Female Population  \\\n",
       "1     Quincy  Massachusetts        41.0          44129.0            49500.0   \n",
       "289   Quincy  Massachusetts        41.0          44129.0            49500.0   \n",
       "426   Quincy  Massachusetts        41.0          44129.0            49500.0   \n",
       "2322  Quincy  Massachusetts        41.0          44129.0            49500.0   \n",
       "2578  Quincy  Massachusetts        41.0          44129.0            49500.0   \n",
       "\n",
       "      Total Population  Number of Veterans  Foreign-born  \\\n",
       "1                93629              4147.0       32935.0   \n",
       "289              93629              4147.0       32935.0   \n",
       "426              93629              4147.0       32935.0   \n",
       "2322             93629              4147.0       32935.0   \n",
       "2578             93629              4147.0       32935.0   \n",
       "\n",
       "      Average Household Size State Code                               Race  \\\n",
       "1                       2.39         MA                              White   \n",
       "289                     2.39         MA                 Hispanic or Latino   \n",
       "426                     2.39         MA  American Indian and Alaska Native   \n",
       "2322                    2.39         MA          Black or African-American   \n",
       "2578                    2.39         MA                              Asian   \n",
       "\n",
       "      Count  \n",
       "1     58723  \n",
       "289    2566  \n",
       "426     351  \n",
       "2322   3917  \n",
       "2578  30473  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demo[df_demo['City']=='Quincy'] # Count is ditributed by Race"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:**\n",
    ">- Unlike Total Population, Count is ditributed by Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bloomington    15\n",
       "Columbia       15\n",
       "Springfield    15\n",
       "Jackson        10\n",
       "Norwalk        10\n",
       "Name: City, dtype: int64"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demo.City.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City\n",
       "Quincy    96030\n",
       "Name: Count, dtype: int64"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demo.query(\"City == 'Quincy'\").groupby('City')['Count'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>Remove Race and Count & Drop Duplicated</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2891, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            City          State  Median Age  Male Population  \\\n",
       "0  Silver Spring       Maryland        33.8          40601.0   \n",
       "1         Quincy  Massachusetts        41.0          44129.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "\n",
       "   Average Household Size State Code  \n",
       "0                    2.60         MD  \n",
       "1                    2.39         MA  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demo.drop(columns=['Race', 'Count'], inplace=True)\n",
    "print(df_demo.shape)\n",
    "df_demo.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(596, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            City          State  Median Age  Male Population  \\\n",
       "0  Silver Spring       Maryland        33.8          40601.0   \n",
       "1         Quincy  Massachusetts        41.0          44129.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "\n",
       "   Average Household Size State Code  \n",
       "0                    2.60         MD  \n",
       "1                    2.39         MA  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demo.drop_duplicates(inplace=True)\n",
    "print(df_demo.shape)\n",
    "df_demo.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demo[['City', 'State']].duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>Merge with \"Airport Codes\" to get local airport code</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(596, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(853, 12)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_demo.shape)\n",
    "df_port_us_l.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The same city has many airports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_demo2 = pd.merge(df_demo, df_port_us_l[['municipality', 'name', 'local_code']], how='left', \n",
    "#                     left_on='City', right_on='municipality')\n",
    "\n",
    "# df_demo2 = df_demo2.sort_values('City')\n",
    "# print(df_demo2.shape)\n",
    "# df_demo2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>GroupBy State</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL</td>\n",
       "      <td>36.228571</td>\n",
       "      <td>497248.0</td>\n",
       "      <td>552381.0</td>\n",
       "      <td>1049629</td>\n",
       "      <td>71543.0</td>\n",
       "      <td>52154.0</td>\n",
       "      <td>2.434286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>AK</td>\n",
       "      <td>32.200000</td>\n",
       "      <td>152945.0</td>\n",
       "      <td>145750.0</td>\n",
       "      <td>298695</td>\n",
       "      <td>27492.0</td>\n",
       "      <td>33258.0</td>\n",
       "      <td>2.770000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     State State Code  Median Age  Male Population  Female Population  \\\n",
       "0  Alabama         AL   36.228571         497248.0           552381.0   \n",
       "1   Alaska         AK   32.200000         152945.0           145750.0   \n",
       "\n",
       "   Total Population  Number of Veterans  Foreign-born  Average Household Size  \n",
       "0           1049629             71543.0       52154.0                2.434286  \n",
       "1            298695             27492.0       33258.0                2.770000  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demo_st = df_demo.groupby(['State', 'State Code'], as_index=False).agg({'Median Age': 'mean','Male Population': 'sum', \n",
    "                    'Female Population': 'sum', 'Total Population': 'sum', 'Number of Veterans': 'sum',\n",
    "                    'Foreign-born': 'sum', 'Average Household Size': 'mean'})\n",
    "print(df_demo_st.shape)\n",
    "df_demo_st.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_demo_st.to_csv(\"input_data/us-states-demographics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>Create an S3 bucket and save cleaned data in</font>\n",
    "https://stackoverflow.com/questions/38154040/save-dataframe-to-csv-directly-to-s3-python/56275519#56275519"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bucket name: nagy99\n",
    "    - Bucket name must be globally unique and must not contain spaces or uppercase letters. \n",
    "- AWS Region: us-west-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aws_credentials = { \"key\": \"***\", \"secret\": \"***\", \"token\": \"***\" } \n",
    "# df.to_csv(\"s3://nagy99/example.csv\", index=False, storage_options=aws_credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step3'></a>\n",
    "### Step 3: Define the Data Model\n",
    "<ul>\n",
    " <li><a href=\"#intro\">Project Summary</a></li>\n",
    " <li><a href=\"#step1\">Step 1: Scope the Project and Gather Data</a></li>\n",
    " <li><a href=\"#step2\">Step 2: Explore and Assess the Data</a></li>\n",
    " <li><a href=\"#step3\"><b>Step 3: Define the Data Model</b></a></li>\n",
    " <li><a href=\"#step4\">Step 4: Run ETL to Model the Data</a></li>\n",
    " <li><a href=\"#step5\">Step 5: Complete Project Write Up</a></li>\n",
    " </ul>\n",
    " \n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "We will use a \"Star Schema\" Model <br>\n",
    "**Advantages of Star Schema:** \n",
    "- **Simpler Queries** <br>\n",
    "Join logic of star schema is quite cinch in comparison to other join logic which are needed to fetch data from a transactional schema that is highly normalized.\n",
    "- **Simplified Business Reporting Logic** <br>\n",
    "In comparison to a transactional schema that is highly normalized, the star schema makes simpler common business reporting logic, such as of reporting and period-over-period.\n",
    "- **Feeding Cubes** <br>\n",
    "Star schema is widely used by all OLAP systems to design OLAP cubes efficiently. In fact, major OLAP systems deliver a ROLAP mode of operation which can use a star schema as a source without designing a cube structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fact Table\n",
    "Since we're interested in the flow of travellers through the united states. The i94 data will serve as our fact table. \n",
    "\n",
    "- 1. immigration \n",
    "\n",
    "| - | Col | Description|\n",
    "| --- | ---: | :---| \n",
    "|1|cicid|Application number / Citizenship and Immigration C...|\n",
    "|**2**|**arrival_year**|**Arrival Year**|\n",
    "|**3**|**arrival_month**|**Arrival Month**|\n",
    "|4|citizinship|Country Immigrant is Originally From (country of citizernship)|\n",
    "|5|residence|Country of Immigrant Residence|\n",
    "|6|port|AIR / SEAPORT of entry into the US<br> ('XXX': 'NOT REPORTED/UNKNOWN' - '888': 'UNIDENTIFED AIR / SEAPORT' -'UNK': 'UNKNOWN POE')|\n",
    "|**7**|**arrival_date**|**Arrival Date to USA**|\n",
    "|8|travel_mode| (1: 'Air' - 2: 'Sea' - 3: 'Land' -  9: 'Not reported') |\n",
    "|9|us_state|U.S. State / Address of Immigrant Inside USA <br> ('99'='All Other Codes') <br> actually representing the final address of the migrants, that is where they currently live in the US.|\n",
    "|**10**|**departure_date**|**Departure Date from the USA**|\n",
    "|**11**|**age**|**Age of Respondent in Years**|\n",
    "|12|visa_category|Visa codes collapsed into three categories <br> (Business - Pleasure - Student)|\n",
    "|13|dep_issued_visa|Department of State where where Visa was issued - CIC does not use <br> This is where your visa was issued. It will be a U.S. embassy or U.S. consulate.|\n",
    "|**14**|**visa_expiration_date**|**Character Date Field - Date to which admitted to U.S. (allowed to stay until) - CIC does not use <br>  visa expiration date  <br>**|\n",
    "|15|gender|Non-immigrant sex|\n",
    "|16|airline|Airline used to arrive in U.S.|\n",
    "|17|admission_number|Admission Number - An 11-digit number assigned to an alien when he enters the Unites States.|\n",
    "|18|flight_number|Flight number of Airline used to arrive in U.S.|\n",
    "|19|visa_type|VISATYPE - Class of admission legally admitting the non-immigrant to temporarily stay in U.S.|\n",
    "\n",
    "\n",
    "  \n",
    "### Dimension Tables\n",
    "\n",
    "- 2. date - to aggregate the data suing various time units <br>\n",
    "     |-- arrdate: date (nullable = true) <br>\n",
    "     |-- arrival_day: integer (nullable = true) <br>\n",
    "     |-- arrival_week: integer (nullable = true) <br>\n",
    "     |-- arrival_month: integer (nullable = true) <br>\n",
    "     |-- arrival_year: integer (nullable = true) <br>\n",
    "     |-- arrival_weekday: integer (nullable = true) <br>\n",
    "<br> <br> \n",
    "- 3. demographics - To look at the demographic data of the areas with the most travelers <br>\n",
    "     |-- City: string (nullable = true) <br>\n",
    "     |-- State: string (nullable = true) <br>\n",
    "     |-- median_age: double (nullable = true) <br>\n",
    "     |-- male_population: integer (nullable = true) <br>\n",
    "     |-- female_population: integer (nullable = true) <br>\n",
    "     |-- total_population: integer (nullable = true) <br>\n",
    "     |-- n_veterans: integer (nullable = true) <br>\n",
    "     |-- foreign_born: integer (nullable = true) <br>\n",
    "     |-- avg_household_size: double (nullable = true) <br>\n",
    "     |-- state_code: string (nullable = true) <br>\n",
    "     |-- Race: string (nullable = true) <br>\n",
    "     |-- Count: integer (nullable = true) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Extraction:**\n",
    "- Load all the datasets from CSV and SAS data files;\n",
    "\n",
    "**Data Transformation and Loading:**\n",
    "\n",
    "**fact_immigration:**\n",
    "- Convert Dates (sas / string) to DateTime\n",
    "- Add Visa Categories (1=Business - 2=Pleasure - 3=Student)\n",
    "- Add travel modes (1=Air - 2=Sea - 3=Land - 9=Not Reported)\n",
    "- Write to parquet\n",
    "\n",
    "**dim_time:**\n",
    "- Get all the arrival dates from the immigration data_set;\n",
    "- extract year, month, day, week from the date and insert all the values in the dim_time table;\n",
    "- Write to parquet\n",
    "\n",
    "**dim_city_demographics:**\n",
    "- Rename Columns\n",
    "- Write to parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step4'></a>\n",
    "### Step 4: Run Pipelines to Model the Data \n",
    "<ul>\n",
    " <li><a href=\"#intro\">Project Summary</a></li>\n",
    " <li><a href=\"#step1\">Step 1: Scope the Project and Gather Data</a></li>\n",
    " <li><a href=\"#step2\">Step 2: Explore and Assess the Data</a></li>\n",
    " <li><a href=\"#step3\">Step 3: Define the Data Model</a></li>\n",
    " <li><a href=\"#step4\"><b>Step 4: Run ETL to Model the Data</b></a></li>\n",
    " <li><a href=\"#step5\">Step 5: Complete Project Write Up</a></li>\n",
    " </ul>\n",
    " \n",
    "<a id='model'></a>\n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model.\n",
    "<ul>\n",
    " <li><a href=\"#model\"><b>4.1 Create the data model</b></a></li>\n",
    " <li><a href=\"#check\">4.2 Data Quality Checks</a></li>\n",
    " </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://knowledge.udacity.com/questions/566319\n",
    "\n",
    "- If your scope aligns with the idea of providing analytics for specific use case, creating a data warehouse is the right approach. Data lake is a storage space for both structured and unstructured raw data. \n",
    "- Whereas, ETL is performed to create a structured data for the type of analysis viz (data warehouse object). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/22 04:51:38 WARN Utils: Your hostname, Mahmouds-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.1.3 instead (on interface en0)\n",
      "22/11/22 04:51:38 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "https://repos.spark-packages.org/ added as a remote repository with the name: repo-1\n",
      ":: loading settings :: url = jar:file:/Users/mnagy99/opt/anaconda3/lib/python3.8/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "Ivy Default Cache set to: /Users/mnagy99/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/mnagy99/.ivy2/jars\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-f55bfbac-c19e-4519-93f7-a5037024f1a7;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.hadoop#hadoop-aws;2.7.0 in central\n",
      "\tfound org.apache.hadoop#hadoop-common;2.7.0 in central\n",
      "\tfound org.apache.hadoop#hadoop-annotations;2.7.0 in central\n",
      "\tfound com.google.guava#guava;11.0.2 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.0 in central\n",
      "\tfound commons-cli#commons-cli;1.2 in central\n",
      "\tfound org.apache.commons#commons-math3;3.1.1 in central\n",
      "\tfound xmlenc#xmlenc;0.52 in central\n",
      "\tfound commons-httpclient#commons-httpclient;3.1 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound commons-codec#commons-codec;1.4 in central\n",
      "\tfound commons-io#commons-io;2.4 in central\n",
      "\tfound commons-net#commons-net;3.1 in central\n",
      "\tfound commons-collections#commons-collections;3.2.1 in central\n",
      "\tfound javax.servlet#servlet-api;2.5 in central\n",
      "\tfound org.mortbay.jetty#jetty;6.1.26 in central\n",
      "\tfound org.mortbay.jetty#jetty-util;6.1.26 in central\n",
      "\tfound com.sun.jersey#jersey-core;1.9 in central\n",
      "\tfound com.sun.jersey#jersey-json;1.9 in central\n",
      "\tfound org.codehaus.jettison#jettison;1.1 in central\n",
      "\tfound com.sun.xml.bind#jaxb-impl;2.2.3-1 in central\n",
      "\tfound javax.xml.bind#jaxb-api;2.2.2 in central\n",
      "\tfound javax.xml.stream#stax-api;1.0-2 in central\n",
      "\tfound javax.activation#activation;1.1 in central\n",
      "\tfound org.codehaus.jackson#jackson-core-asl;1.9.13 in central\n",
      "\tfound org.codehaus.jackson#jackson-mapper-asl;1.9.13 in central\n",
      "\tfound org.codehaus.jackson#jackson-jaxrs;1.9.13 in central\n",
      "\tfound org.codehaus.jackson#jackson-xc;1.9.13 in central\n",
      "\tfound com.sun.jersey#jersey-server;1.9 in central\n",
      "\tfound asm#asm;3.2 in central\n",
      "\tfound log4j#log4j;1.2.17 in central\n",
      "\tfound net.java.dev.jets3t#jets3t;0.9.0 in central\n",
      "\tfound org.apache.httpcomponents#httpclient;4.2.5 in central\n",
      "\tfound org.apache.httpcomponents#httpcore;4.2.5 in central\n",
      "\tfound com.jamesmurty.utils#java-xmlbuilder;0.4 in central\n",
      "\tfound commons-lang#commons-lang;2.6 in central\n",
      "\tfound commons-configuration#commons-configuration;1.6 in central\n",
      "\tfound commons-digester#commons-digester;1.8 in central\n",
      "\tfound commons-beanutils#commons-beanutils;1.7.0 in central\n",
      "\tfound commons-beanutils#commons-beanutils-core;1.8.0 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.10 in central\n",
      "\tfound org.apache.avro#avro;1.7.4 in central\n",
      "\tfound com.thoughtworks.paranamer#paranamer;2.3 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.0.4.1 in central\n",
      "\tfound org.apache.commons#commons-compress;1.4.1 in central\n",
      "\tfound org.tukaani#xz;1.0 in central\n",
      "\tfound com.google.protobuf#protobuf-java;2.5.0 in central\n",
      "\tfound com.google.code.gson#gson;2.2.4 in central\n",
      "\tfound org.apache.hadoop#hadoop-auth;2.7.0 in central\n",
      "\tfound org.apache.directory.server#apacheds-kerberos-codec;2.0.0-M15 in central\n",
      "\tfound org.apache.directory.server#apacheds-i18n;2.0.0-M15 in central\n",
      "\tfound org.apache.directory.api#api-asn1-api;1.0.0-M20 in central\n",
      "\tfound org.apache.directory.api#api-util;1.0.0-M20 in central\n",
      "\tfound org.apache.zookeeper#zookeeper;3.4.6 in central\n",
      "\tfound org.slf4j#slf4j-log4j12;1.7.10 in central\n",
      "\tfound io.netty#netty;3.6.2.Final in central\n",
      "\tfound org.apache.curator#curator-framework;2.7.1 in central\n",
      "\tfound org.apache.curator#curator-client;2.7.1 in central\n",
      "\tfound com.jcraft#jsch;0.1.42 in central\n",
      "\tfound org.apache.curator#curator-recipes;2.7.1 in central\n",
      "\tfound org.apache.htrace#htrace-core;3.1.0-incubating in central\n",
      "\tfound javax.servlet.jsp#jsp-api;2.1 in central\n",
      "\tfound jline#jline;0.9.94 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-databind;2.2.3 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-annotations;2.2.3 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.2.3 in central\n",
      "\tfound com.amazonaws#aws-java-sdk;1.7.4 in central\n",
      "\tfound joda-time#joda-time;2.12.1 in central\n",
      "\t[2.12.1] joda-time#joda-time;[2.2,)\n",
      ":: resolution report :: resolve 5477ms :: artifacts dl 146ms\n",
      "\t:: modules in use:\n",
      "\tasm#asm;3.2 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk;1.7.4 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-annotations;2.2.3 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.2.3 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-databind;2.2.3 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.0 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.2.4 from central in [default]\n",
      "\tcom.google.guava#guava;11.0.2 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;2.5.0 from central in [default]\n",
      "\tcom.jamesmurty.utils#java-xmlbuilder;0.4 from central in [default]\n",
      "\tcom.jcraft#jsch;0.1.42 from central in [default]\n",
      "\tcom.sun.jersey#jersey-core;1.9 from central in [default]\n",
      "\tcom.sun.jersey#jersey-json;1.9 from central in [default]\n",
      "\tcom.sun.jersey#jersey-server;1.9 from central in [default]\n",
      "\tcom.sun.xml.bind#jaxb-impl;2.2.3-1 from central in [default]\n",
      "\tcom.thoughtworks.paranamer#paranamer;2.3 from central in [default]\n",
      "\tcommons-beanutils#commons-beanutils;1.7.0 from central in [default]\n",
      "\tcommons-beanutils#commons-beanutils-core;1.8.0 from central in [default]\n",
      "\tcommons-cli#commons-cli;1.2 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.4 from central in [default]\n",
      "\tcommons-collections#commons-collections;3.2.1 from central in [default]\n",
      "\tcommons-configuration#commons-configuration;1.6 from central in [default]\n",
      "\tcommons-digester#commons-digester;1.8 from central in [default]\n",
      "\tcommons-httpclient#commons-httpclient;3.1 from central in [default]\n",
      "\tcommons-io#commons-io;2.4 from central in [default]\n",
      "\tcommons-lang#commons-lang;2.6 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\tcommons-net#commons-net;3.1 from central in [default]\n",
      "\tio.netty#netty;3.6.2.Final from central in [default]\n",
      "\tjavax.activation#activation;1.1 from central in [default]\n",
      "\tjavax.servlet#servlet-api;2.5 from central in [default]\n",
      "\tjavax.servlet.jsp#jsp-api;2.1 from central in [default]\n",
      "\tjavax.xml.bind#jaxb-api;2.2.2 from central in [default]\n",
      "\tjavax.xml.stream#stax-api;1.0-2 from central in [default]\n",
      "\tjline#jline;0.9.94 from central in [default]\n",
      "\tjoda-time#joda-time;2.12.1 from central in [default]\n",
      "\tlog4j#log4j;1.2.17 from central in [default]\n",
      "\tnet.java.dev.jets3t#jets3t;0.9.0 from central in [default]\n",
      "\torg.apache.avro#avro;1.7.4 from central in [default]\n",
      "\torg.apache.commons#commons-compress;1.4.1 from central in [default]\n",
      "\torg.apache.commons#commons-math3;3.1.1 from central in [default]\n",
      "\torg.apache.curator#curator-client;2.7.1 from central in [default]\n",
      "\torg.apache.curator#curator-framework;2.7.1 from central in [default]\n",
      "\torg.apache.curator#curator-recipes;2.7.1 from central in [default]\n",
      "\torg.apache.directory.api#api-asn1-api;1.0.0-M20 from central in [default]\n",
      "\torg.apache.directory.api#api-util;1.0.0-M20 from central in [default]\n",
      "\torg.apache.directory.server#apacheds-i18n;2.0.0-M15 from central in [default]\n",
      "\torg.apache.directory.server#apacheds-kerberos-codec;2.0.0-M15 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-annotations;2.7.0 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-auth;2.7.0 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;2.7.0 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-common;2.7.0 from central in [default]\n",
      "\torg.apache.htrace#htrace-core;3.1.0-incubating from central in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.2.5 from central in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.2.5 from central in [default]\n",
      "\torg.apache.zookeeper#zookeeper;3.4.6 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-core-asl;1.9.13 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-jaxrs;1.9.13 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-mapper-asl;1.9.13 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-xc;1.9.13 from central in [default]\n",
      "\torg.codehaus.jettison#jettison;1.1 from central in [default]\n",
      "\torg.mortbay.jetty#jetty;6.1.26 from central in [default]\n",
      "\torg.mortbay.jetty#jetty-util;6.1.26 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.10 from central in [default]\n",
      "\torg.slf4j#slf4j-log4j12;1.7.10 from central in [default]\n",
      "\torg.tukaani#xz;1.0 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.0.4.1 from central in [default]\n",
      "\txmlenc#xmlenc;0.52 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   68  |   1   |   0   |   0   ||   68  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-f55bfbac-c19e-4519-93f7-a5037024f1a7\n",
      "\tconfs: [default]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t0 artifacts copied, 68 already retrieved (0kB/26ms)\n",
      "22/11/22 04:51:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/11/22 04:51:46 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/11/22 04:51:57 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "Duration: 0.9164968490600586 Minutes                                            \n"
     ]
    }
   ],
   "source": [
    "# - %run -i '.py'\n",
    "# - !python .py\n",
    "\n",
    "t0 = time()\n",
    "!python spark_etl.py\n",
    "print(f\"Duration: {(time()-t0)/60} Minutes\")\n",
    "\n",
    "### (Using S3 with Local Mode!!)\n",
    "### This is not recommended at all in production\n",
    "### This is going to load the data all the way from amazon,\n",
    "### and into the memory of jupyter Notebook Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3096313\n",
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- arrival_year: double (nullable = true)\n",
      " |-- arrival_month: double (nullable = true)\n",
      " |-- citizinship: double (nullable = true)\n",
      " |-- residence: double (nullable = true)\n",
      " |-- port: string (nullable = true)\n",
      " |-- arrival_date: date (nullable = true)\n",
      " |-- travel_mode: string (nullable = true)\n",
      " |-- departure_date: date (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- visa_category: string (nullable = true)\n",
      " |-- dep_issued_visa: string (nullable = true)\n",
      " |-- visa_expiration_date: date (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admission_number: double (nullable = true)\n",
      " |-- flight_number: string (nullable = true)\n",
      " |-- visa_type: string (nullable = true)\n",
      " |-- us_state: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>arrival_year</th>\n",
       "      <th>arrival_month</th>\n",
       "      <th>citizinship</th>\n",
       "      <th>residence</th>\n",
       "      <th>port</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>travel_mode</th>\n",
       "      <th>departure_date</th>\n",
       "      <th>age</th>\n",
       "      <th>visa_category</th>\n",
       "      <th>dep_issued_visa</th>\n",
       "      <th>visa_expiration_date</th>\n",
       "      <th>gender</th>\n",
       "      <th>airline</th>\n",
       "      <th>admission_number</th>\n",
       "      <th>flight_number</th>\n",
       "      <th>visa_type</th>\n",
       "      <th>us_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1172235.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>ORL</td>\n",
       "      <td>2016-04-07</td>\n",
       "      <td>Air</td>\n",
       "      <td>2016-04-09</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>None</td>\n",
       "      <td>2016-07-05</td>\n",
       "      <td>F</td>\n",
       "      <td>CM</td>\n",
       "      <td>5.573992e+10</td>\n",
       "      <td>00434</td>\n",
       "      <td>WT</td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1409781.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>SFR</td>\n",
       "      <td>2016-04-08</td>\n",
       "      <td>Air</td>\n",
       "      <td>2016-04-13</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Business</td>\n",
       "      <td>GUZ</td>\n",
       "      <td>2016-10-06</td>\n",
       "      <td>M</td>\n",
       "      <td>CX</td>\n",
       "      <td>9.299930e+10</td>\n",
       "      <td>00872</td>\n",
       "      <td>B1</td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1172236.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>ORL</td>\n",
       "      <td>2016-04-07</td>\n",
       "      <td>Air</td>\n",
       "      <td>2016-04-09</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Business</td>\n",
       "      <td>None</td>\n",
       "      <td>2016-07-05</td>\n",
       "      <td>F</td>\n",
       "      <td>B6</td>\n",
       "      <td>5.577795e+10</td>\n",
       "      <td>01714</td>\n",
       "      <td>WB</td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1409853.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>HAM</td>\n",
       "      <td>2016-04-08</td>\n",
       "      <td>Air</td>\n",
       "      <td>2016-04-09</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Business</td>\n",
       "      <td>GUZ</td>\n",
       "      <td>2016-10-07</td>\n",
       "      <td>M</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.302473e+10</td>\n",
       "      <td>00657</td>\n",
       "      <td>B1</td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1172237.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>ORL</td>\n",
       "      <td>2016-04-07</td>\n",
       "      <td>Air</td>\n",
       "      <td>2016-04-10</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>None</td>\n",
       "      <td>2016-07-05</td>\n",
       "      <td>F</td>\n",
       "      <td>B6</td>\n",
       "      <td>5.574426e+10</td>\n",
       "      <td>01724</td>\n",
       "      <td>WT</td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cicid  arrival_year  arrival_month  citizinship  residence port  \\\n",
       "0  1172235.0        2016.0            4.0        129.0      129.0  ORL   \n",
       "1  1409781.0        2016.0            4.0        245.0      245.0  SFR   \n",
       "2  1172236.0        2016.0            4.0        129.0      129.0  ORL   \n",
       "3  1409853.0        2016.0            4.0        245.0      245.0  HAM   \n",
       "4  1172237.0        2016.0            4.0        129.0      129.0  ORL   \n",
       "\n",
       "  arrival_date travel_mode departure_date   age visa_category dep_issued_visa  \\\n",
       "0   2016-04-07         Air     2016-04-09  31.0      Pleasure            None   \n",
       "1   2016-04-08         Air     2016-04-13  36.0      Business             GUZ   \n",
       "2   2016-04-07         Air     2016-04-09  41.0      Business            None   \n",
       "3   2016-04-08         Air     2016-04-09  23.0      Business             GUZ   \n",
       "4   2016-04-07         Air     2016-04-10  49.0      Pleasure            None   \n",
       "\n",
       "  visa_expiration_date gender airline  admission_number flight_number  \\\n",
       "0           2016-07-05      F      CM      5.573992e+10         00434   \n",
       "1           2016-10-06      M      CX      9.299930e+10         00872   \n",
       "2           2016-07-05      F      B6      5.577795e+10         01714   \n",
       "3           2016-10-07      M      DL      9.302473e+10         00657   \n",
       "4           2016-07-05      F      B6      5.574426e+10         01724   \n",
       "\n",
       "  visa_type us_state  \n",
       "0        WT       FL  \n",
       "1        B1       FL  \n",
       "2        WB       FL  \n",
       "3        B1       FL  \n",
       "4        WT       FL  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get filepath to immigration data file\n",
    "path = \"output_data/immigration\"\n",
    "    \n",
    "# read song data file\n",
    "df_immigration = spark.read\\\n",
    "          .parquet(path)\n",
    "\n",
    "print(df_immigration.count())\n",
    "df_immigration.printSchema()\n",
    "\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_immigration.limit(5).toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create initial date df from arrdate column\n",
    "date_df = df_spark.select(['arrdate']).distinct()\n",
    "\n",
    "# expand df by adding other calendar columns\n",
    "date_df = date_df.withColumn('arrival_day', F.dayofmonth('arrdate'))\n",
    "date_df = date_df.withColumn('arrival_week', F.weekofyear('arrdate'))\n",
    "date_df = date_df.withColumn('arrival_month', F.month('arrdate'))\n",
    "date_df = date_df.withColumn('arrival_year', F.year('arrdate'))\n",
    "date_df = date_df.withColumn('arrival_weekday', F.dayofweek('arrdate'))\n",
    "\n",
    "# # create an id field in calendar df\n",
    "# date_df = date_df.withColumn('id', monotonically_increasing_id())\n",
    "\n",
    "# write the date dimension to parquet file\n",
    "date_df.write.parquet('./output_data/' + \"arrival_dates\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "root\n",
      " |-- arrdate: date (nullable = true)\n",
      " |-- arrival_day: integer (nullable = true)\n",
      " |-- arrival_week: integer (nullable = true)\n",
      " |-- arrival_month: integer (nullable = true)\n",
      " |-- arrival_year: integer (nullable = true)\n",
      " |-- arrival_weekday: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrdate</th>\n",
       "      <th>arrival_day</th>\n",
       "      <th>arrival_week</th>\n",
       "      <th>arrival_month</th>\n",
       "      <th>arrival_year</th>\n",
       "      <th>arrival_weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-04-25</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-04-22</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-04-26</td>\n",
       "      <td>26</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-04-04</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      arrdate  arrival_day  arrival_week  arrival_month  arrival_year  \\\n",
       "0  2016-04-25           25            17              4          2016   \n",
       "1  2016-04-22           22            16              4          2016   \n",
       "2  2016-04-30           30            17              4          2016   \n",
       "3  2016-04-26           26            17              4          2016   \n",
       "4  2016-04-04            4            14              4          2016   \n",
       "\n",
       "   arrival_weekday  \n",
       "0                2  \n",
       "1                6  \n",
       "2                7  \n",
       "3                3  \n",
       "4                2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get filepath to dates data file\n",
    "path = \"output_data/arrival_dates\"\n",
    "    \n",
    "# read data file\n",
    "df_dates = spark.read\\\n",
    "          .parquet(path)\n",
    "\n",
    "# .option(\"recursiveFileLookup\",\"true\")\\ --> This was preventing loading columns partitioned by\n",
    "\n",
    "print(df_dates.count())\n",
    "df_dates.printSchema()\n",
    "\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_dates.limit(5).toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2891\n",
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- median_age: double (nullable = true)\n",
      " |-- male_population: integer (nullable = true)\n",
      " |-- female_population: integer (nullable = true)\n",
      " |-- total_population: integer (nullable = true)\n",
      " |-- n_veterans: integer (nullable = true)\n",
      " |-- foreign_born: integer (nullable = true)\n",
      " |-- avg_household_size: double (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- Count: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>median_age</th>\n",
       "      <th>male_population</th>\n",
       "      <th>female_population</th>\n",
       "      <th>total_population</th>\n",
       "      <th>n_veterans</th>\n",
       "      <th>foreign_born</th>\n",
       "      <th>avg_household_size</th>\n",
       "      <th>state_code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601</td>\n",
       "      <td>41862</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562</td>\n",
       "      <td>30908</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129</td>\n",
       "      <td>49500</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147</td>\n",
       "      <td>32935</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040</td>\n",
       "      <td>46799</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819</td>\n",
       "      <td>8229</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127</td>\n",
       "      <td>87105</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821</td>\n",
       "      <td>33878</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040</td>\n",
       "      <td>143873</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829</td>\n",
       "      <td>86253</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  median_age  male_population  \\\n",
       "0     Silver Spring       Maryland        33.8            40601   \n",
       "1            Quincy  Massachusetts        41.0            44129   \n",
       "2            Hoover        Alabama        38.5            38040   \n",
       "3  Rancho Cucamonga     California        34.5            88127   \n",
       "4            Newark     New Jersey        34.6           138040   \n",
       "\n",
       "   female_population  total_population  n_veterans  foreign_born  \\\n",
       "0              41862             82463        1562         30908   \n",
       "1              49500             93629        4147         32935   \n",
       "2              46799             84839        4819          8229   \n",
       "3              87105            175232        5821         33878   \n",
       "4             143873            281913        5829         86253   \n",
       "\n",
       "   avg_household_size state_code                       Race  Count  \n",
       "0                2.60         MD         Hispanic or Latino  25924  \n",
       "1                2.39         MA                      White  58723  \n",
       "2                2.58         AL                      Asian   4759  \n",
       "3                3.18         CA  Black or African-American  24437  \n",
       "4                2.73         NJ                      White  76402  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get filepath to demographics data file\n",
    "path = \"output_data/demographics\"\n",
    "    \n",
    "# read data file\n",
    "df_demographics = spark.read\\\n",
    "          .option(\"recursiveFileLookup\",\"true\")\\\n",
    "          .parquet(path)\n",
    "\n",
    "print(df_demographics.count())\n",
    "df_demographics.printSchema()\n",
    "\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_demographics.limit(5).toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='check'></a>\n",
    "#### 4.2 Data Quality Checks\n",
    "Build the data pipelines to create the data model.\n",
    "<ul>\n",
    " <li><a href=\"#model\">4.1 Create the data model</a></li>\n",
    " <li><a href=\"#check\"><b>4.2 Data Quality Checks</b></a></li>\n",
    " </ul>\n",
    " \n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform quality checks here\n",
    "\n",
    "def quality_checks(df, table_name):\n",
    "    \"\"\"Count checks on fact and dimension table to ensure completeness of data.\n",
    "    \n",
    "    Args:\n",
    "        df --> spark dataframe \n",
    "        table_name --> corresponding name of table\n",
    "    \"\"\"\n",
    "    total_count = df.count()\n",
    "\n",
    "    if total_count == 0:\n",
    "        print(f\"Data quality check failed for {table_name} with zero records!\")\n",
    "    else:\n",
    "        print(f\"Data quality check passed for {table_name} with {total_count:,} records.\")\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 133:=============================>                         (19 + 4) / 35]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality check passed for fact_immigration with 3,096,313 records.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 133:==========================================>            (27 + 4) / 35]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quality_checks(df_immigration, 'fact_immigration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality check passed for dim_demographics with 2,891 records.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quality_checks(df_demographics, 'dim_demographics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality check passed for dim_dates with 30 records.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quality_checks(df_dates, 'dim_dates')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step5'></a>\n",
    "#### Step 5: Complete Project Write Up\n",
    "<ul>\n",
    " <li><a href=\"#intro\">Project Summary</a></li>\n",
    " <li><a href=\"#step1\">Step 1: Scope the Project and Gather Data</a></li>\n",
    " <li><a href=\"#step2\">Step 2: Explore and Assess the Data</a></li>\n",
    " <li><a href=\"#step3\">Step 3: Define the Data Model</a></li>\n",
    " <li><a href=\"#step4\">Step 4: Run ETL to Model the Data</a></li>\n",
    " <li><a href=\"#step5\"><b>Step 5: Complete Project Write Up</b></a></li>\n",
    " </ul>\n",
    "\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clearly state the rationale for the choice of tools and technologies for the project.**\n",
    "- Consdiering the significant size of the immigration dataset (~ 3 million rows) for only a month, the most sensible technology choice for such an approach would be spark, especially if we were to process data over a longer period of time.\n",
    "\n",
    "- Apache spark was used because of:\n",
    "    - it's ability to handle multiple file formats with large amounts of data.\n",
    "    - Apache Spark offers a lightning-fast unified analytics engine for big data.\n",
    "    - Spark has easy-to-use APIs for operating on large datasets\n",
    "\n",
    "**Propose how often the data should be updated and why.**\n",
    "- The current I94 immigration data is updated monthly, and hence the data will be updated monthly.\n",
    "- A monthly update would be sufficient for the needs of this study.\n",
    "\n",
    "\n",
    "### Write a description of how you would approach the problem differently under the following scenarios:\n",
    "**The data was increased by 100x**\n",
    "- Spark can handle the increase but we would consider increasing the number of nodes in our cluster.\n",
    "- We would still use spark as it as our data processing platform since it is the best suited platform for very large datasets.\n",
    "- Our data would be stored in an Amazon S3 bucket (instead of storing it in the EMR cluster along with the staging tables) and loaded to our staging tables. \n",
    "\n",
    "\n",
    "**The data populates a dashboard that must be updated on a daily basis by 7am every day.**\n",
    "- We would use Apache Airflow to schedule and run data pipelines.\n",
    "\n",
    "\n",
    "**The database needed to be accessed by 100+ people:**\n",
    "- We would move our analytics database into Amazon Redshift\n",
    "- Once the data is ready to be consumed, it would be stored in a postgres database on a redshift cluster that easily supports multiuser access."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
